<!DOCTYPE html>
  <html>
    <head>
      <title>blog_cn</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href=".\katex.min.css">
      
      
      
      
      
      
      
      
      
      

      <style> 
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */
 
      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview   ">
      <h1 class="mume-header" id="%E6%B7%B1%E5%BA%A6%E5%89%96%E6%9E%90-%E5%8F%AF%E5%BE%AE%E5%88%86%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%87%AA%E9%80%82%E9%85%8D%E5%BD%92%E4%B8%80%E5%8C%96-switchable-normalization">深度剖析 | 可微分学习的自适配归一化 (Switchable Normalization)</h1>

<p>作者：罗平、任家敏、彭章琳<br>
编写：吴凌云、张瑞茂、邵文琪、王新江</p>
<p>注：本文出自香港中文大学（CUHK）多媒体实验室和商汤科技研究院（SenseTime Research）。转载需注明作者及出处。原论文参考<a href="https://arxiv.org/abs/1806.10779">arXiv:1806.10779</a>和代码<a href="https://github.com/switchablenorms">Github</a>。</p>
<p><strong>前言</strong>：归一化技术已经成为深度学习系统必不可少的重要组成部分，对优化神经网络的参数、提高泛化性能有着重要作用。这些归一化方法包括但不限于批归一化BN（Batch Normalization），实例归一化IN（Instance Normalization），和层归一化LN（Layer Normalization）。本文作者对归一化方法提出两点思考：第一，归一化虽然提高模型泛化能力，然而归一化层的操作是人工设计的。在实际应用中，解决不同的问题原则上需要设计不同的归一化操作，并没有一个通用的归一化方法能够解决所有应用问题；第二，一个深度神经网络往往包含几十个归一化层，通常这些归一化层都使用同样的归一化操作，因为手工为每一个归一化层设计操作需要进行大量的实验。本文作者提出自适配归一化方法——Switchable Normalization（SN）来解决上述问题。与强化学习不同，SN使用可微分学习，为一个深度网络中的每一个归一化层确定合适的归一化操作。SN不但易于使用而且性能优越（<a href="#4-sn%E7%9A%84%E5%BA%94%E7%94%A8">见第4章</a>）。更重要的是它对归一化方法的理论分析有着重要参考意义（<a href="#3-sn%E7%9A%84%E6%9C%AC%E8%B4%A8">见第3章</a>）。本文涉及的文献<a href="#6-%E7%9B%B8%E5%85%B3%E6%96%87%E7%8C%AE">见第6章</a>。本文共五章，目录如下。</p>
<ul>
<li><a href="#%E6%B7%B1%E5%BA%A6%E5%89%96%E6%9E%90--%E5%8F%AF%E5%BE%AE%E5%88%86%E5%AD%A6%E4%B9%A0%E7%9A%84%E8%87%AA%E9%80%82%E9%85%8D%E5%BD%92%E4%B8%80%E5%8C%96-switchable-normalization">深度剖析 | 可微分学习的自适配归一化 (Switchable Normalization)</a>
<ul>
<li><a href="#1-%E5%88%9D%E6%8E%A2sn">1. 初探SN</a></li>
<li><a href="#2-sn%E7%9A%84%E4%BC%98%E5%8A%BF">2. SN的优势</a></li>
<li><a href="#3-sn%E7%9A%84%E6%9C%AC%E8%B4%A8">3. SN的本质</a>
<ul>
<li><a href="#31-sn%E4%B8%8Eminibatch">3.1 SN与minibatch</a></li>
<li><a href="#32-sn%E8%B0%83%E8%8A%82%E7%94%B1bn%E7%9A%84%E5%9D%87%E5%80%BC%E5%92%8C%E6%96%B9%E5%B7%AE%E6%89%80%E4%BA%A7%E7%94%9F%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96">3.2 SN调节由BN的均值和方差所产生的正则化</a></li>
<li><a href="#33-sn%E4%B8%8Ebngn%E7%9A%84%E6%B3%9B%E5%8C%96%E6%80%A7%E8%83%BD">3.3 SN与BN，GN的泛化性能</a></li>
<li><a href="#34-sn%E4%B8%8E%E5%8F%AF%E5%BE%AE%E5%88%86%E7%BB%93%E6%9E%84%E6%90%9C%E7%B4%A2-darts">3.4 SN与可微分结构搜索 (DARTS)</a>
<ul>
<li><a href="#%E7%BD%91%E7%BB%9C%E5%8F%82%E6%95%B0%E4%B8%8E%E6%8E%A7%E5%88%B6%E5%8F%82%E6%95%B0%E7%9A%84%E7%AB%9E%E4%BA%89">网络参数与控制参数的竞争</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#4-sn%E7%9A%84%E5%BA%94%E7%94%A8">4. SN的应用</a>
<ul>
<li><a href="#41-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB">4.1 图像分类</a>
<ul>
<li><a href="#sn%E4%B8%8Ebngn%E6%AF%94%E8%BE%83">SN与BN，GN比较</a></li>
<li><a href="#sn%E4%B8%8Einlnbrnbrk%E6%AF%94%E8%BE%83">SN与IN，LN，BRN，BRK比较</a></li>
</ul>
</li>
<li><a href="#42-%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%88%86%E5%89%B2">4.2 物体检测与分割</a></li>
<li><a href="#43-%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB">4.3 图像风格迁移</a></li>
<li><a href="#44-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%90%9C%E7%B4%A2">4.4 神经网络结构搜索</a></li>
</ul>
</li>
<li><a href="#5-%E7%BB%93%E8%AF%AD">5. 结语</a></li>
<li><a href="#6-%E7%9B%B8%E5%85%B3%E6%96%87%E7%8C%AE">6. 相关文献</a></li>
</ul>
</li>
</ul>
<h2 class="mume-header" id="1-%E5%88%9D%E6%8E%A2sn">1. 初探SN</h2>

<p>Switchable Normalization（SN）统一了实例归一化Instance Normalization（IN），层归一化Layer Normalization（LN），和批归一化Batch Normalization（BN）的各种操作。假设一个卷积神经网络（CNN）的一个隐含卷积层的输入数据可表示为具有四个维度的特征图，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mo>(</mo><mi>N</mi><mo separator="true">,</mo><mi>C</mi><mo separator="true">,</mo><mi>H</mi><mo separator="true">,</mo><mi>W</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(N, C, H, W)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit" style="margin-right:0.07153em;">C</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit" style="margin-right:0.08125em;">H</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="mclose">)</span></span></span></span>。这里每个维度分别代表样本数目（minibatch size），通道数目（number of channels），通道的高（height），和通道的宽（width）。假设每一个像素表示为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mrow><mi>n</mi><mi>c</mi><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">h_{ncij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="base"><span class="mord"><span class="mord mathit">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span><span class="mord mathit mtight">c</span><span class="mord mathit mtight">i</span><span class="mord mathit mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"></span></span></span></span></span></span></span></span>，这里<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi><mo separator="true">,</mo><mi>c</mi><mo separator="true">,</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow><annotation encoding="application/x-tex">n,c,i,j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.65952em;"></span><span class="strut bottom" style="height:0.85396em;vertical-align:-0.19444em;"></span><span class="base"><span class="mord mathit">n</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit">c</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit">i</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit" style="margin-right:0.05724em;">j</span></span></span></span>为上述四个维度的下标。SN对<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>h</mi><mrow><mi>n</mi><mi>c</mi><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">h_{ncij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="base"><span class="mord"><span class="mord mathit">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span><span class="mord mathit mtight">c</span><span class="mord mathit mtight">i</span><span class="mord mathit mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"></span></span></span></span></span></span></span></span>进行归一化操作，并输出归一化后的像素值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mover accent="true"><mrow><mi>h</mi></mrow><mo>^</mo></mover><mrow><mi>n</mi><mi>c</mi><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\hat{h}_{ncij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.9578799999999998em;"></span><span class="strut bottom" style="height:1.2439879999999999em;vertical-align:-0.286108em;"></span><span class="base"><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9578799999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathit">h</span></span></span><span style="top:-3.26344em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;">^</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span><span class="mord mathit mtight">c</span><span class="mord mathit mtight">i</span><span class="mord mathit mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"></span></span></span></span></span></span></span></span>。SN的计算公式如下：<br>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mover accent="true"><mrow><mi>h</mi></mrow><mo>^</mo></mover><mrow><mi>n</mi><mi>c</mi><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><mi>γ</mi><mfrac><mrow><msub><mi>h</mi><mrow><mi>n</mi><mi>c</mi><mi>i</mi><mi>j</mi></mrow></msub><mo>−</mo><msub><mi mathvariant="normal">Σ</mi><mrow><mi>k</mi><mo>∈</mo><mi mathvariant="normal">Ω</mi></mrow></msub><msub><mi>w</mi><mi>k</mi></msub><msub><mi>μ</mi><mi>k</mi></msub></mrow><mrow><msqrt><mrow><msub><mi mathvariant="normal">Σ</mi><mrow><mi>k</mi><mo>∈</mo><mi mathvariant="normal">Ω</mi></mrow></msub><msubsup><mi>w</mi><mi>k</mi><mo mathvariant="normal">′</mo></msubsup><msubsup><mi>σ</mi><mi>k</mi><mn>2</mn></msubsup><mo>+</mo><mi>ϵ</mi></mrow></msqrt></mrow></mfrac><mo>+</mo><mi>β</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\hat{h}_{ncij}=\gamma\frac{h_{ncij}-\Sigma_{k\in\Omega} w_k\mu_k}
{\sqrt{\Sigma_{k\in\Omega}w_k^\prime\sigma_k^2+\epsilon}}+\beta.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.37144em;"></span><span class="strut bottom" style="height:2.5014399999999997em;vertical-align:-1.13em;"></span><span class="base"><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.9578799999999998em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathit">h</span></span></span><span style="top:-3.26344em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;">^</span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span><span class="mord mathit mtight">c</span><span class="mord mathit mtight">i</span><span class="mord mathit mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"></span></span></span></span></span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mord mathit" style="margin-right:0.05556em;">γ</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.37144em;"><span style="top:-2.1777em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord sqrt"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9322999999999999em;"><span class="svg-align" style="top:-3.2em;"><span class="pstrut" style="height:3.2em;"></span><span class="mord" style="padding-left:1em;"><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999985em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">∈</span><span class="mord mtight">Ω</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17737em;"></span></span></span></span></span><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.733692em;"><span style="top:-2.398692em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.0448em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">′</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.30130799999999996em;"></span></span></span></span></span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7959079999999998em;"><span style="top:-2.398692em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.0448em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.30130799999999996em;"></span></span></span></span></span><span class="mord rule" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mord rule" style="margin-right:0.2222222222222222em;"></span><span class="mord mathit">ϵ</span></span></span><span style="top:-2.8923em;"><span class="pstrut" style="height:3.2em;"></span><span class="hide-tail" style="min-width:1.02em;height:1.28em;"><svg width="400em" height="1.28em" viewBox="0 0 400000 1296" preserveAspectRatio="xMinYMin slice"><path d="M263,681c0.7,0,18,39.7,52,119c34,79.3,68.167,
158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120c340,-704.7,510.7,-1060.3,512,-1067
c4.7,-7.3,11,-11,19,-11H40000v40H1012.3s-271.3,567,-271.3,567c-38.7,80.7,-84,
175,-136,283c-52,108,-89.167,185.3,-111.5,232c-22.3,46.7,-33.8,70.3,-34.5,71
c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1s-109,-253,-109,-253c-72.7,-168,-109.3,
-252,-110,-252c-10.7,8,-22,16.7,-34,26c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26
s76,-59,76,-59s76,-60,76,-60z M1001 80H40000v40H1012z"></path></svg></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3077000000000001em;"></span></span></span></span></span></span><span style="top:-3.15em;"><span class="pstrut" style="height:3em;"></span><span class="stretchy" style="height:0.2em;"><svg width="400em" height="0.2em" viewBox="0 0 400000 200" preserveAspectRatio="xMinYMin slice"><path d="M0 80H400000 v40H0z M0 80H400000 v40H0z"></path></svg></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathit">h</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.311664em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight">n</span><span class="mord mathit mtight">c</span><span class="mord mathit mtight">i</span><span class="mord mathit mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"></span></span></span></span></span><span class="mord rule" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mord rule" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999985em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">∈</span><span class="mord mtight">Ω</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17737em;"></span></span></span></span></span><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mord"><span class="mord mathit">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.13em;"></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord rule" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mord rule" style="margin-right:0.2222222222222222em;"></span><span class="mord mathit" style="margin-right:0.05278em;">β</span><span class="mord">.</span></span></span></span></span></p>
<p>上述定义与BN，IN，和LN的定义相似。他们都学习了缩放系数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>γ</mi></mrow><annotation encoding="application/x-tex">\gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.05556em;">γ</span></span></span></span>和偏移系数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.05278em;">β</span></span></span></span>。主要的区别在于SN的统计信息（即均值<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="base"><span class="mord mathit">μ</span></span></span></span>和方差<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>σ</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\sigma^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:0.8141079999999999em;vertical-align:0em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span>），不像IN只是在一个通道中计算的，也不像LN只是在一个层中计算，而是在一个集合<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ω</mi></mrow><annotation encoding="application/x-tex">\Omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span class="mord">Ω</span></span></span></span>当中选择合适的归一化方法来加权平均的。这个集合定义为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Ω</mi><mo>=</mo><mo>{</mo><mrow><mi mathvariant="normal">b</mi><mi mathvariant="normal">n</mi></mrow><mo separator="true">,</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mrow><mo separator="true">,</mo><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">n</mi></mrow><mo>}</mo></mrow><annotation encoding="application/x-tex">\Omega=\{\mathrm{bn},\mathrm{in},\mathrm{ln}\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mord">Ω</span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathrm">b</span><span class="mord mathrm">n</span></span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathrm">i</span><span class="mord mathrm">n</span></span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathrm">l</span><span class="mord mathrm">n</span></span><span class="mclose">}</span></span></span></span>。<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">w_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>w</mi><mi>k</mi><mo mathvariant="normal">′</mo></msubsup></mrow><annotation encoding="application/x-tex">w_k^\prime</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.751892em;"></span><span class="strut bottom" style="height:1.035em;vertical-align:-0.2831079999999999em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">′</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"></span></span></span></span></span></span></span></span>则为相应统计量对应的权重系数。下图直观的展示了SN的基本原理。</p>
<p><img src="./1.jpg" alt="@&#x56FE;1 &#x81EA;&#x9002;&#x914D;&#x5F52;&#x4E00;&#x5316;&#x56FE;&#x5F62;&#x89E3;&#x91CA;| center | 600x0"></p>
<p>图1为SN的直观图形解释。SN中每个样本每个通道（<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>H</mi><mo>×</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">H\times W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.08125em;">H</span><span class="mord rule" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mord rule" style="margin-right:0.2222222222222222em;"></span><span class="mord mathit" style="margin-right:0.13889em;">W</span></span></span></span>）的均值和方差，由BN、IN、LN三种不同统计方法计算得到的均值和方差共同决定。</p>
<p>在SN中，均值的加权系数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">w_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>的计算方法如下：<br>
<span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mi>k</mi></msub><mo>=</mo><mfrac><mrow><msup><mi>e</mi><msub><mi>λ</mi><mi>k</mi></msub></msup></mrow><mrow><msub><mi mathvariant="normal">Σ</mi><mrow><mi>z</mi><mo>∈</mo><mo>{</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mrow><mo separator="true">,</mo><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">n</mi></mrow><mo separator="true">,</mo><mrow><mi mathvariant="normal">b</mi><mi mathvariant="normal">n</mi></mrow><mo>}</mo></mrow></msub><msup><mi>e</mi><msub><mi>λ</mi><mi>z</mi></msub></msup></mrow></mfrac><mo separator="true">,</mo><mtext> </mtext><mtext> </mtext><mtext> </mtext><mi>k</mi><mo>∈</mo><mo>{</mo><mrow><mi mathvariant="normal">b</mi><mi mathvariant="normal">n</mi></mrow><mo separator="true">,</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mrow><mo separator="true">,</mo><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">n</mi></mrow><mo>}</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">w_k=\frac{e^{\lambda_k}}{\Sigma_{z\in\{\mathrm{in},\mathrm{ln},\mathrm{bn}\}}e^{\lambda_z}},~
~~k\in\{\mathrm{bn},\mathrm{in},\mathrm{ln}\},</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.5261079999999998em;"></span><span class="strut bottom" style="height:2.5673079999999997em;vertical-align:-1.0412em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5261079999999998em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right:0.04398em;">z</span><span class="mrel mtight">∈</span><span class="mopen mtight">{</span><span class="mord mtight"><span class="mord mathrm mtight">i</span><span class="mord mathrm mtight">n</span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathrm mtight">l</span><span class="mord mathrm mtight">n</span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathrm mtight">b</span><span class="mord mathrm mtight">n</span></span><span class="mclose mtight">}</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"></span></span></span></span></span><span class="mord"><span class="mord mathit">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7751079999999999em;"><span style="top:-2.989em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathit mtight">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathit mtight" style="margin-right:0.04398em;">z</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.15em;"><span class="pstrut" style="height:3em;"></span><span class="stretchy" style="height:0.2em;"><svg width="400em" height="0.2em" viewBox="0 0 400000 200" preserveAspectRatio="xMinYMin slice"><path d="M0 80H400000 v40H0z M0 80H400000 v40H0z"></path></svg></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathit">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathit mtight">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:0em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0412em;"></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mspace"> </span><span class="mspace"> </span><span class="mspace"> </span><span class="mord mathit" style="margin-right:0.03148em;">k</span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mopen">{</span><span class="mord"><span class="mord mathrm">b</span><span class="mord mathrm">n</span></span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathrm">i</span><span class="mord mathrm">n</span></span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathrm">l</span><span class="mord mathrm">n</span></span><span class="mclose">}</span><span class="mpunct">,</span></span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>λ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">λ_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>为三个维度统计量对应的参数。为了与网络参数（如卷积核）区分，这些参数称为控制参数。这些控制参数均初始为1，在反向传播时进行优化学习。该计算公式即利用softmax函数对优化参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>λ</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">λ_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>进行归一化，计算统计量最终的加权系数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">w_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>。因此，所有加权系数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">w_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>的和为1，每个加权系数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>w</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">w_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>的值都在0和1之间。类似的，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>w</mi><mi>k</mi><mo mathvariant="normal">′</mo></msubsup></mrow><annotation encoding="application/x-tex">w_k^\prime</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.751892em;"></span><span class="strut bottom" style="height:1.035em;vertical-align:-0.2831079999999999em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">′</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"></span></span></span></span></span></span></span></span>可以由另外的三个参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>λ</mi><mrow><mi mathvariant="normal">b</mi><mi mathvariant="normal">n</mi></mrow><mo mathvariant="normal">′</mo></msubsup></mrow><annotation encoding="application/x-tex">\lambda_\mathrm{bn}^\prime</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.751892em;"></span><span class="strut bottom" style="height:1.035em;vertical-align:-0.2831079999999999em;"></span><span class="base"><span class="mord"><span class="mord mathit">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">b</span><span class="mord mathrm mtight">n</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">′</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>λ</mi><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mrow><mo mathvariant="normal">′</mo></msubsup></mrow><annotation encoding="application/x-tex">\lambda_\mathrm{in}^\prime</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.751892em;"></span><span class="strut bottom" style="height:1.016394em;vertical-align:-0.264502em;"></span><span class="base"><span class="mord"><span class="mord mathit">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.435498em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">i</span><span class="mord mathrm mtight">n</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">′</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.264502em;"></span></span></span></span></span></span></span></span>，和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>λ</mi><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">n</mi></mrow><mo mathvariant="normal">′</mo></msubsup></mrow><annotation encoding="application/x-tex">\lambda_\mathrm{ln}^\prime</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.751892em;"></span><span class="strut bottom" style="height:1.035em;vertical-align:-0.2831079999999999em;"></span><span class="base"><span class="mord"><span class="mord mathit">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">l</span><span class="mord mathrm mtight">n</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">′</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"></span></span></span></span></span></span></span></span>计算得出，且<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi mathvariant="normal">Σ</mi><mrow><mi>k</mi><mo>∈</mo><mi mathvariant="normal">Ω</mi></mrow></msub><msubsup><mi>w</mi><mi>k</mi><mo mathvariant="normal">′</mo></msubsup><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\Sigma_{k\in\Omega}w_k^\prime=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.751892em;"></span><span class="strut bottom" style="height:1.035em;vertical-align:-0.2831079999999999em;"></span><span class="base"><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999985em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">∈</span><span class="mord mtight">Ω</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.17737em;"></span></span></span></span></span><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">′</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"></span></span></span></span></span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mord">1</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">∀</mi><msubsup><mi>w</mi><mi>k</mi><mo mathvariant="normal">′</mo></msubsup><mo>∈</mo><mo>[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo>]</mo></mrow><annotation encoding="application/x-tex">\forall w_k^\prime\in[0,1]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.751892em;"></span><span class="strut bottom" style="height:1.035em;vertical-align:-0.2831079999999999em;"></span><span class="base"><span class="mord">∀</span><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4168920000000003em;margin-left:-0.02691em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">′</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"></span></span></span></span></span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∈</span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mopen">[</span><span class="mord">0</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord">1</span><span class="mclose">]</span></span></span></span>。因此，相对于BN，SN只额外增加了<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>λ</mi><mrow><mi mathvariant="normal">b</mi><mi mathvariant="normal">n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\lambda_\mathrm{bn}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">b</span><span class="mord mathrm mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>λ</mi><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\lambda_\mathrm{in}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31750199999999995em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">i</span><span class="mord mathrm mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>λ</mi><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\lambda_\mathrm{ln}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base"><span class="mord"><span class="mord mathit">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">l</span><span class="mord mathrm mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>λ</mi><mrow><mi mathvariant="normal">b</mi><mi mathvariant="normal">n</mi></mrow><mo mathvariant="normal">′</mo></msubsup></mrow><annotation encoding="application/x-tex">\lambda_\mathrm{bn}^\prime</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.751892em;"></span><span class="strut bottom" style="height:1.035em;vertical-align:-0.2831079999999999em;"></span><span class="base"><span class="mord"><span class="mord mathit">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">b</span><span class="mord mathrm mtight">n</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">′</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>λ</mi><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mrow><mo mathvariant="normal">′</mo></msubsup></mrow><annotation encoding="application/x-tex">\lambda_\mathrm{in}^\prime</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.751892em;"></span><span class="strut bottom" style="height:1.016394em;vertical-align:-0.264502em;"></span><span class="base"><span class="mord"><span class="mord mathit">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.435498em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">i</span><span class="mord mathrm mtight">n</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">′</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.264502em;"></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>λ</mi><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">n</mi></mrow><mo mathvariant="normal">′</mo></msubsup></mrow><annotation encoding="application/x-tex">\lambda_\mathrm{ln}^\prime</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.751892em;"></span><span class="strut bottom" style="height:1.035em;vertical-align:-0.2831079999999999em;"></span><span class="base"><span class="mord"><span class="mord mathit">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">l</span><span class="mord mathrm mtight">n</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">′</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"></span></span></span></span></span></span></span></span> 6个控制参数。</p>
<h2 class="mume-header" id="2-sn%E7%9A%84%E4%BC%98%E5%8A%BF">2. SN的优势</h2>

<p>相比于其他归一化方法，SN有以下性质：</p>
<ul>
<li><strong>鲁棒性</strong> ：对mini-batch尺寸的不敏感使其精度在各种batch size设置下都保持稳定。特别是在batch size受限的视觉任务中相对有利，例如物体检测、实例分割、视频识别等。</li>
<li><strong>通用性</strong> ：以往不同的归一化方法依赖不同维度的统计信息，针对不同的视觉任务需要选择不同的网络结构。精细的手动设计和繁琐的实验验证使实际应用中的模型选择变得非常困难。SN适用于各种网络结构包括CNNs和RNNs，并能够解决多种视觉任务。</li>
<li><strong>多样性</strong> ：SN为神经网络不同归一化层选择不同操作，拓展了归一化技术的边界，具有重要意义。直观而言，现有的方法都是对整个网络的所有层保持相同的归一化操作。然而，神经网络学习得到的高层特征具有高层语义，而低层特征学习底层视觉信息。我们应该为处在神经网络不同位置、不同深度的归一化层选择不同的操作。问题在于一方面很难手动选择整个网络的不同归一化操作，另一方面通过实验选择单一的归一化操作不一定能达到最优性能。</li>
</ul>
<h2 class="mume-header" id="3-sn%E7%9A%84%E6%9C%AC%E8%B4%A8">3. SN的本质</h2>

<p>本章结合SN的基本原理，分析SN的性质。</p>
<h3 class="mume-header" id="31-sn%E4%B8%8Eminibatch">3.1 SN与minibatch</h3>

<p>由前面的介绍可知，minibatch size的变化对BN的影响最大，因为BN使用的均值和方差是在minibatch当中统计的。minibatch越小，这些统计量的估计会带有更大的噪声，<em>对模型训练产生过大的规范化（regularization）作用或称正则化作用</em>，从而影响模型的泛化性能。而IN，LN和GN（group normalization）在计算统计量时虽然与minibatch无关，却由于缺乏正则化能力在大的minibatch时无法达到BN的精度（与BN不同，这些技术单独使用往往导致较明显的过拟合现象）。SN通过学习不同归一化方法的相互作用（权重系数），克服了上述问题。无论minibatch大还是小，SN都能自适配的学习出合适的归一化方式，保持高精度。总的来说：</p>
<blockquote>
<p>minibatch越小，SN中BN的权重系数越小，IN和LN的权重系数则越大；<br>
minibatch越大，SN中BN的权重系数越大，IN和LN的权重系数越小。</p>
</blockquote>
<p>下图为SN在不同minibatch size下自主选择BN，IN，LN的权重系数的展示。括号表示（GPU数目，每个GPU样本数即minibatch）。在训练中，梯度通过在所有GPUs中平均进行估计，而所有归一化方法的统计量只在单独一个GPU当中计算。可以看出，随着minibatch的不断减小，BN的权重越来越低，IN和LN的权重越来越高。当minibatch size等于1时，BN的权重为零，因为此时在训练当中BN等效于IN。</p>
<p><img src="./2.jpg" alt="@&#x56FE;2 SN&#x6743;&#x91CD;&#x7CFB;&#x6570;&#x5C55;&#x793A;. &#x4E8C;&#x5143;&#x7EC4;(x,x)&#x5185;&#x5206;&#x522B;&#x4EE3;&#x8868;GPU&#x7684;&#x6570;&#x76EE;&#x548C;&#x6BCF;&#x4E2A;GPU&#x7684;&#x6837;&#x672C;&#x6570;(mini-batch size)| center | 520x0"></p>
<h3 class="mume-header" id="32-sn%E8%B0%83%E8%8A%82%E7%94%B1bn%E7%9A%84%E5%9D%87%E5%80%BC%E5%92%8C%E6%96%B9%E5%B7%AE%E6%89%80%E4%BA%A7%E7%94%9F%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96">3.2 SN调节由BN的均值和方差所产生的正则化</h3>

<p>由前面的介绍可知，BN在计算统计量过程会引入随机噪声。<em>这些随机噪声为模型带来正则化作用（regularization），该作用的强度与minibatch size成反比</em>。直观的说，由BN的均值和方差分别产生的正则化对模型训练会产生不同的影响。具体来说，计算样本均值引入的噪声要弱于估计样本方差引入的噪声（噪声越大，正则化作用越强）。SN通过分别调节它们的权重，来增加或者减少模型的正则化作用。进一步地，SN的自主选择过程旨在抑制噪声。统计量带来的噪声越大抑制越厉害。可以理解为：</p>
<blockquote>
<p>minibatch较小时，BN中variance的权重会更小于mean的权重</p>
</blockquote>
<p>下图为SN在ResNet50不同的blocks中选择BN，IN和LN权重系数的展示。(a)中minibatch size为32，(b)中minibatch size为2。可以看出对于BN，其均值和方差的加权系数不一样。对比(a)和(b)我们发现，当minibatch size为32时，BN的均值和方差的具有较大的权重；当batchsize为2时，BN中variance的权重会被降低，从而降低估计variance时引入的噪声的影响。</p>
<p><img src="./3.jpg" alt="@&#x56FE;3.1 SN&#x4E0D;&#x540C;block&#x7684;&#x6743;&#x91CD;&#x7CFB;&#x6570;&#x5C55;&#x793A;. &#x4E8C;&#x5143;&#x7EC4;(x,x)&#x5185;&#x5206;&#x522B;&#x4EE3;&#x8868;GPU&#x7684;&#x6570;&#x76EE;&#x548C;&#x6BCF;&#x4E2A;GPU&#x7684;&#x6837;&#x672C;&#x6570;(mini-batch size)| center | 600x0"><br>
<img src="./4.jpg" alt="@&#x56FE;3.2 SN&#x4E0D;&#x540C;block&#x7684;&#x6743;&#x91CD;&#x7CFB;&#x6570;&#x5C55;&#x793A;. &#x4E8C;&#x5143;&#x7EC4;(x,x)&#x5185;&#x5206;&#x522B;&#x4EE3;&#x8868;GPU&#x7684;&#x6570;&#x76EE;&#x548C;&#x6BCF;&#x4E2A;GPU&#x7684;&#x6837;&#x672C;&#x6570;(mini-batch size)| center | 600x0"></p>
<h3 class="mume-header" id="33-sn%E4%B8%8Ebngn%E7%9A%84%E6%B3%9B%E5%8C%96%E6%80%A7%E8%83%BD">3.3 SN与BN，GN的泛化性能</h3>

<p>基于SN的设计，我们发现SN不仅可以解决因minibatch太小而导致的BN中噪声太大的问题，并且通过引入其他的归一化方法提升了模型的性能。而且在minibatch较大时发挥出BN的优势，弥补其他归一化方法的缺陷。可以理解为：</p>
<blockquote>
<p>SN是一种覆盖特征图张量各个维度来计算统计信息的归一化方法，不依赖minibatch size的同时对各个维度统计有很好的鲁棒性。</p>
</blockquote>
<p>下图展示出SN，BN，GN在不同minibatch size下的性能，三者都使用ResNet50在ImageNet中训练。纵坐标为ImageNet验证集top-1准确率。可以看出，BN对minibatch size非常敏感，在minibatch较小时性能较差；GN的性能相对稳定，但在minibatch较大时性能不如BN；而SN不仅克服了BN对batchsize较为敏感的问题，在各个minibatch size下都能表现稳定，而且达到较优的模型性能。</p>
<p><img src="./5.jpg" alt="@&#x56FE;4 SN&#x4E0E;BN&#xFF0C;GN&#x6CDB;&#x5316;&#x66F2;&#x7EBF;&#x5C55;&#x793A;. &#x4E8C;&#x5143;&#x7EC4;(x,x)&#x5185;&#x5206;&#x522B;&#x4EE3;&#x8868;GPU&#x7684;&#x6570;&#x76EE;&#x548C;&#x6BCF;&#x4E2A;GPU&#x7684;&#x6837;&#x672C;&#x6570;(mini-batch size)| center | 300x0"></p>
<h3 class="mume-header" id="34-sn%E4%B8%8E%E5%8F%AF%E5%BE%AE%E5%88%86%E7%BB%93%E6%9E%84%E6%90%9C%E7%B4%A2-darts">3.4 SN与可微分结构搜索 (DARTS)</h3>

<p>SN与DARTS解决的是不同的问题，但它们之间有着较深的联系。DARTS使用可微分学习来解决神经网络结构搜索问题。在DARTS中，一个神经网络被定义成图（graph）。图上的点（node）和边（edge）分别表示神经网络隐含层的输入和在这个输入上定义的操作。DARTS与SN相似的地方在于，它们都使用了softmax函数来选择不同的操作。不同的是，DARTS选择convolution、pooling等操作，而SN选择归一化操作。那么是否能够说明它们本质一样？答案是否定的。</p>
<p>回答上面的问题关键在于本章强调的归一化操作对训练带来的规范化（正则化）作用。SN实际上学习了不同正则化作用之间的一阶关系，这种正则化作用使得网络模型的参数（表示为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>）和控制参数（SN里用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span class="mord mathit">λ</span></span></span></span>表示）能够在<em>训练集</em>当中一起优化，并不会导致过拟合。然而DARTS的控制参数也是softmax函数的参数（DARTS论文里用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>表示），但是这些参数则<em>不能</em>与网络参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>一起在训练集优化。因为若同时在训练集优化<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>，会使得<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>倾向与选择复杂度高的操作来过拟合训练集，导致较差的泛化性能。总体来说，</p>
<blockquote>
<p>SN对归一化操作的选择旨在提高泛化性能；然而DARTS对卷积或池化（pooling）等操作的选择，容易导致过拟合。</p>
</blockquote>
<p>由于上述原因，SN与DARTS采用不同的训练方式。SN的方式更为简单直接，网络参数与控制参数同时使用SGD和BP优化就可以了。然而，训练DARTS使用的是两轮迭代的方法（与绝大多数强化学习方法相似）：1）固定<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>，并在训练集优化<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>，即<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>min</mi><mo>⁡</mo><mi>θ</mi></msub><mrow><mi mathvariant="script">L</mi></mrow><mo>(</mo><mi>θ</mi><mo separator="true">,</mo><mi>α</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">\min_\theta\mathcal{L}(\theta,\alpha)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mop"><span class="mop">min</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathcal">L</span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit" style="margin-right:0.0037em;">α</span><span class="mclose">)</span></span></span></span>。这里<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mi mathvariant="script">L</mi></mrow></mrow><annotation encoding="application/x-tex">\mathcal{L}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.68333em;"></span><span class="strut bottom" style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span class="mord"><span class="mord mathcal">L</span></span></span></span></span>代表神经网络定义的损失函数。2）固定<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>，并在<em>校验集</em>优化<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>。这里DARTS使用了稍微复杂的方式，即<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>min</mi><mo>⁡</mo><mi>α</mi></msub><mrow><mi mathvariant="script">L</mi></mrow><mo>(</mo><msup><mi>θ</mi><mo>∗</mo></msup><mo separator="true">,</mo><mi>α</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">\min_\alpha\mathcal{L}(\theta^*,\alpha)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mop"><span class="mop">min</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.0037em;">α</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathcal">L</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit" style="margin-right:0.0037em;">α</span><span class="mclose">)</span></span></span></span>，而<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>θ</mi><mo>∗</mo></msup><mo>=</mo><mi>arg</mi><mo>⁡</mo><msub><mi>min</mi><mo>⁡</mo><mi>θ</mi></msub><mrow><mi mathvariant="script">L</mi></mrow><mo>(</mo><mi>θ</mi><mo separator="true">,</mo><mi>α</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">\theta^*=\arg\min_\theta\mathcal{L}(\theta,\alpha)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mord rule" style="margin-right:0.2777777777777778em;"></span><span class="mop">ar<span style="margin-right:0.01389em;">g</span></span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mop"><span class="mop">min</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathit mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"></span></span></span></span></span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathcal">L</span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="mpunct">,</span><span class="mord rule" style="margin-right:0.16666666666666666em;"></span><span class="mord mathit" style="margin-right:0.0037em;">α</span><span class="mclose">)</span></span></span></span>。第二步中的<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>θ</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">\theta^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span>实际上是在当前模型结构下对网络参数<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>的预测。换句话说，更新网络结构<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>考虑了网络参数将会如何跟随着变化。这是一种网络参数与控制参数的二者竞争。这种竞争与对抗网络GAN（generative adversarial network）的竞争不同。在传统的GAN博弈中，两个竞争者同时产生决策。而DARTS借鉴的博弈方法中，网络结构的学习一般在博弈过程中占主导地位（先确定网络结构，再训练网络参数）。这一点也在更新<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>时会预测<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>θ</mi><mo>∗</mo></msup></mrow><annotation encoding="application/x-tex">\theta^*</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span class="mord"><span class="mord mathit" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span></span></span></span></span></span></span></span>的优化过程中体现。</p>
<h4 class="mume-header" id="%E7%BD%91%E7%BB%9C%E5%8F%82%E6%95%B0%E4%B8%8E%E6%8E%A7%E5%88%B6%E5%8F%82%E6%95%B0%E7%9A%84%E7%AB%9E%E4%BA%89">网络参数与控制参数的竞争</h4>

<p>在DARTS的论文中表示，上述迭代优化方式借鉴了经济学里经典的“主导-跟随”模型（Stackelberg Leadership Model）。该模型是一种理想模型，一般的情况描述了占主导地位的大企业（<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>）与小企业（<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>）之间的博弈。大企业先决策（如定价），小企业跟随。主导企业考虑小企业的决策函数（DARTS中代表<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>随<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>变化的函数），把小企业的决策考虑在自己的决策当中（如考虑整体市场供给和需求等），从而达到利润最大化。在DARTS中，可以认为这是鼓励学习多样的网络结构。而在SN中，可以认为其优化过程是该竞争模型的简化和近似。这种简化使得SN更容易优化与应用。能够进行近似的原因是隐晦的，这是由于<em>SN学习的归一化操作对网络参数带来了规范化作用，隐含的限制了网络参数的模（或可探索范围），变相的鼓励网络结构的优化</em>。总结来说：</p>
<blockquote>
<p>在SN中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>同时在训练集中优化；<br>
在DARTS中，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.02778em;">θ</span></span></span></span>在训练集优化，<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span class="mord mathit" style="margin-right:0.0037em;">α</span></span></span></span>在测试集优化，需要迭代进行。</p>
</blockquote>
<h2 class="mume-header" id="4-sn%E7%9A%84%E5%BA%94%E7%94%A8">4. SN的应用</h2>

<p>为了进一步说明SN的通用性，我们在多个具有挑战性的视觉问题上对其效果进行了验证，包括在ImageNet上进行图像分类，在MS-COCO进行物体检测与分割，图像风格化，以及网络结构搜索。</p>
<h3 class="mume-header" id="41-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB">4.1 图像分类</h3>

<p>自2009年首次提出以来，ImageNet就一直是图像分类任务的标准评测集合。我们将利用ImageNet上经典的1000类分类任务对BN,GN和SN进行综合的比较。实验所使用的神经网络结构是ResNet50, 为了公平对比，原始网络中的BN将会替换为GN和SN，而保持其他训练设置不变。</p>
<h4 class="mume-header" id="sn%E4%B8%8Ebngn%E6%AF%94%E8%BE%83">SN与BN，GN比较</h4>

<p>下表总结了SN和BN、GN在不同的minibatch size情况下的分类准确率，表格底部给出了不同归一化技术之间的准确率差距。基于实验结果，我们可以得到以下结论：</p>
<ul>
<li><strong>多卡小batch size:</strong> SN和GN对minibatch size有很好的鲁棒性，而BN的性能随着minibatch size的减小会有显著的下降，这对于极耗显存的任务（如物体检测与分割等）是十分不利的。</li>
<li><strong>多卡不同的batch size:</strong> SN不仅对于minibatch size有很好的鲁棒性，而且所有结果都优于GN或与其相当。一定程度上可以说兼顾了实验室级别的训练需求和工业级别的训练需求。同时满足数据并行和模型并行的训练需求。</li>
<li><strong>单卡不同的batch size:</strong>  SN在单个GPU上的结果同样优于BN和GN。此时用于估计梯度的样本数目比较小。一定程度上可以说SN是当前兼顾通用性与准确性的较优的归一化方式。</li>
</ul>
<p><img src="./6.jpg" alt="@&#x8868;4.1 ImageNet&#x6570;&#x636E;&#x96C6;&#x4E0A;SN&#x548C;BN&#x3001;GN&#x7684;&#x5206;&#x7C7B;&#x51C6;&#x786E;&#x7387;&#x5BF9;&#x6BD4;&#x3002;&#x4E8C;&#x5143;&#x7EC4;(x,x)&#x5185;&#x5206;&#x522B;&#x4EE3;&#x8868;GPU&#x7684;&#x6570;&#x76EE;&#x548C;&#x6BCF;&#x4E2A;GPU&#x7684;&#x6837;&#x672C;&#x6570;(mini-batch size) | center | 600x0"></p>
<h4 class="mume-header" id="sn%E4%B8%8Einlnbrnbrk%E6%AF%94%E8%BE%83">SN与IN，LN，BRN，BRK比较</h4>

<p>除了BN和GN，其他归一化方法在图像分类问题上效果如何呢？</p>
<p><strong>SN <em>vs.</em> IN和LN</strong>：IN和LN虽然在图像风格化和LSTM应用中取得了不错的效果，但并不适用于图像分类。在通用设置(8,32)上，SN、IN和LN在ResNet50上的准确率分别是76.9%、71.6%和74.7%，SN的结果分别比IN和LN高5.3%和2.2%。</p>
<p><strong>SN <em>vs.</em> BRN和BKN</strong>：BRN （Batch Renormalization）和BKN（Batch Kalman Normalization）是BN的两个变种方法，他们都可以减弱BN对minibatch size的敏感性。在(8,4)这种小minibatch size的情况下，BRN在最优超参设置下可以达到73.7%的准确率，比原始BN 72.7%高了1%，但是依然比SN 75.9%低了2.2%。而BKN在(8,32)下的准确率为76.8%，与SN的76.9%的结果相当。可是BKN在训练过程中需要估算协方差矩阵，这导致了计算过程需要更多的参数以及更大的运算量。</p>
<h3 class="mume-header" id="42-%E7%89%A9%E4%BD%93%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%88%86%E5%89%B2">4.2 物体检测与分割</h3>

<p>与图像分类不同，对于物体检测和分割任务，输入图像的尺度相对比较大，因此每张图片所需要的显存也明显上升。在显存有限的情况下，minibatch中图片的数量将明显下降，通常每张GPU能够处理的图片数量在1到2张，在这种情况下，BN的效果会明显下降。为了应对这种问题，早期的解决办法是将BN层固定，使其变为一个线性变化层，失去了有效归一化的作用。<br>
与上述的解决方案相比，SN是一种更为可行的替代方案，且能够有效拓展到不同的检测模型，以及不同的深度学习平台上。我们实现了基于Pytorch和CUDA-Detectron的两个版本。使用了三种设置进行SN与BN和GN的比较：</p>
<ol>
<li>Faster R-CNN + ResNet50 (基于Pytorch)</li>
<li>Faster R-CNN + FPN + ResNet50 (Detectron)</li>
<li>Mask R-CNN + FPN + ResNet50 (Detectron)</li>
</ol>
<p><img src="./7.jpg" alt="@&#x8868;4.2 Faster R-CNN + ResNet50 &#x5728;COCO&#x6570;&#x636E;&#x96C6;&#x4E0A;&#x7684;&#x68C0;&#x6D4B;&#x7ED3;&#x679C;&#x3002;&#x5176;&#x4E2D;backbone &#x6307;&#x7684;&#x662F; conv4&#x4E4B;&#x524D;&#x7684;&#x5C42;&#xFF0C; &#x7528;&#x4E8E;&#x62BD;&#x53D6;&#x7279;&#x5F81;&#xFF1B;head&#x6307;&#x4EE3;&#x7684;&#x662F;conv5&#xFF0C;&#x7528;&#x4E8E;&#x5206;&#x7C7B;&#x548C;&#x4F4D;&#x7F6E;&#x56DE;&#x5F52;&#x3002;| center | 600x0"></p>
<p>如上表所示，我们给出了SN和BN、GN在<strong>设置1中的性能结果。</strong> 其中 BN<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mrow></mrow><mo>†</mo></msup></mrow><annotation encoding="application/x-tex">^\dagger</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8491079999999999em;"></span><span class="strut bottom" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="base"><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">†</span></span></span></span></span></span></span></span></span></span></span> 表示BN层中的相关参数是固定的。我们得到以下结论：</p>
<ul>
<li>Finetuning的情况下，使用较小的minibatch，固定BN中的参数效果要明显优于对BN中的参数进行微调。</li>
<li>Finetuning的情况下，用SN和GN替换所有的BN层，SN的效果达到最优，AP为33.0。</li>
<li>From Scratch 的情况下，使用<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mrow></mrow><mo>‡</mo></msup></mrow><annotation encoding="application/x-tex">^\ddagger</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8491079999999999em;"></span><span class="strut bottom" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="base"><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">‡</span></span></span></span></span></span></span></span></span></span></span>符号进行标记 。可以看到SN的性能依旧是最优的，比BN的AP高9.5，比GN的AP高1.2。一定程度上说明SN是对检测算法十分有效地归一化算法。</li>
</ul>
<p><img src="./8.jpg" alt="@&#x8868;4.3 Faster R-CNN + ResNet50 + FPN  &#x5728;COCO&#x6570;&#x636E;&#x96C6;&#x4E0A;&#x7684;&#x68C0;&#x6D4B;&#x7ED3;&#x679C;&#x3002;| center | 600x0"></p>
<p>如上表所示，我们给出了SN和BN、GN在<strong>设置2的性能结果。</strong> 我们获得的结论有：</p>
<ul>
<li>底层固定BN<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mrow></mrow><mo>†</mo></msup></mrow><annotation encoding="application/x-tex">^\dagger</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8491079999999999em;"></span><span class="strut bottom" style="height:0.8491079999999999em;vertical-align:0em;"></span><span class="base"><span class="mord"><span></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491079999999999em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">†</span></span></span></span></span></span></span></span></span></span></span>，上层使用SN和GN，SN效果要略微高于GN（38.0 vs. 37.2）</li>
<li>底层和上层都使用SN或GN 替换BN，SN的效果要明显高于GN （39.3 vs. 38.2）</li>
<li>在整个网络使用SN或GN的性能要优于在多卡之间同步BN参数的方法37.8。</li>
</ul>
<p>如下表所示，我们给出了SN和BN、GN在<strong>设置3的性能结果。</strong> 我们能够得到与设置2相类似的结论。经过上述3个实验，我们一定程度上证明了在一个模型中使用可配置化的归一化方法，能够提升归一化方法对任务的适应性，进而提升性能。同时也充分证明了SN可以有效地应用于检测和分割这两大重要的视觉任务上。</p>
<p><img src="./9.jpg" alt="@&#x8868;4.4 Mask R-CNN + ResNet50 + FPN  &#x5728;COCO&#x6570;&#x636E;&#x96C6;&#x4E0A;&#x7684;&#x68C0;&#x6D4B;&#x53CA;&#x5206;&#x5272;&#x7ED3;&#x679C;&#x3002;| center | 600x0"></p>
<h3 class="mume-header" id="43-%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB">4.3 图像风格迁移</h3>

<p>图像风格迁移是指使用参考图像的风格去渲染目标图像，使得目标图像的风格能够有效地迁移到目标图像上。近期的工作[]在网络中使用IN，并采用联合优化特征重建函数和风格重建函数的方法，得到了令人满意的风格化结果。其中特征重建函数约束了风格化后的结果图像的内容要与原图尽可能相似，而风格重建函数目标则是使风格化图像在风格上要与目标风格图尽可能靠近。该工作也展示了在图像风格化任务上，IN的效果要好于BN。<br>
如前文所述，SN是一种能够有效适应不同任务地归一化方式。因此它同样适用于图像风格迁移任务。我们将原来VGG16网络中的IN替换为SN。下图(a)对比了两种重建函数之和的loss曲线，可以看到SN对比IN和BN有明显优势。并且给出了风格化后的可视化结果。</p>
<p><img src="./10.jpg" alt="@&#x56FE;5 (a)&#x56FE;&#x50CF;&#x98CE;&#x683C;&#x5316;&#x4E2D;BN&#x3001;IN&#x3001;SN&#x7684;loss&#x66F2;&#x7EBF;&#x3002;(b)&#x7F51;&#x7EDC;&#x7ED3;&#x6784;&#x641C;&#x7D22;&#x4E2D;CIFAR10&#x6570;&#x636E;&#x96C6;&#x6D4B;&#x8BD5;&#x51C6;&#x786E;&#x7387;&#x3002;| center | 420x0"></p>
<p><img src="./11.jpg" alt="@&#x56FE;6 &#x56FE;&#x50CF;&#x98CE;&#x683C;&#x5316;&#x53EF;&#x89C6;&#x5316;&#x7ED3;&#x679C;&#x3002;&#x7B2C;&#x4E00;&#x5217;&#x4E3A;&#x539F;&#x56FE;&#x53CA;&#x76EE;&#x6807;&#x98CE;&#x683C;&#xFF0C;&#x7B2C;&#x4E8C;&#x5217;&#x4E3A;IN&#x7ED3;&#x679C;&#xFF0C;&#x7B2C;&#x4E09;&#x5217;&#x4E3A;SN&#x7ED3;&#x679C;&#x3002;| center | 800x0"></p>
<h3 class="mume-header" id="44-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E6%90%9C%E7%B4%A2">4.4 神经网络结构搜索</h3>

<p>随着近年Google提出AutoML项目，深度神经网络结构的自动化搜索受到了学界和工业界的广泛关注。其中，LSTM被应用于高效的网络结构搜索（ENAS）中。ENAS将一个卷积神经网络定义为由若干个相同的卷积结构块堆叠而成，ENAS通过搜索卷积结构块中的结构来实现高效网络结构搜索。</p>
<p>整个ENAS包含两步：训练控制器和训练子模型。1) <strong>控制器</strong> 实际上是一个LSTM。LSTM通过增强学习算法（Reinforce learning）来更新参数，从而确定卷积结构块中的结构。2) <strong>子模型</strong>是指通过叠加卷积结构块得到的完整的卷积神经网络，它是通过SGD更新参数。</p>
<p>为了验证SN同样适用于LSTM，我们在LSTM控制器中分别加入SN、LN和GN来提升结构搜索的性能。实验中我们用LSTM控制器来学习网络结构，在CIFAR10数据集上测试学习到的网络结构的分类准确率。由于BN无法应用到LSTM中，同时在全连接层中IN等价于LN，在实验中SN采用了LN和GN的组合。上图(b)展示了在CIFAR10上的分类准确率，对比LN和GN的结果，可以看到SN明显提高了ENAS的性能。</p>
<h2 class="mume-header" id="5-%E7%BB%93%E8%AF%AD">5. 结语</h2>

<p>总的来说，SN是一种任务与数据驱动的归一化方法。它对各种归一化技术对训练所产生的影响进行激励或者抑制，从而取得最优性能。本文作者的团队通过对各种归一化方法进行深入的分析，发现SN学习得到的权重系数能够准确的反映各种归一化技术在不同训练条件下的理论性质。相信随着这一研究的不断深入，这些数学性质将会被更清楚的描述出来。</p>
<h2 class="mume-header" id="6-%E7%9B%B8%E5%85%B3%E6%96%87%E7%8C%AE">6. 相关文献</h2>

<ol>
<li>BN: S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In ICML, 2015</li>
<li>LN: J. L. Ba, J. R. Kiros, and G. E. Hinton. Layer normalization. arXiv:1607.06450, 2016.</li>
<li>IN: X. Huang and S. Belongie. Arbitrary style transfer in real-time with adaptive instance normalization. arXiv: 1703.06868, 2017</li>
<li>GN: Y. Wu and K. He. Group normalization. arXiv:1803.08494, 2018</li>
<li>BRN: S. Ioffe. Batch renormalization: Towards reducing minibatch dependence in batch-normalized models. arXiv:1702.03275, 2017.</li>
<li>BKN: G.Wang, J. Peng, P. Luo, X.Wang, and L. Lin. Batch kalman normalization: Towards training deep neural networks with micro-batches. arXiv:1802.03133, 2018</li>
<li>DARTS: Hanxiao Liu, Karen Simonyan, Yiming Yang, DARTS: Differentiable Architecture Search, arXiv:1806.09055, 2018</li>
<li>Faster R-CNN: S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. arXiv:1506.01497, 2015</li>
<li>Mask R-CNN: K. He, G. Gkioxari, P. Dollr, and R. Girshick. Mask r-cnn. ICCV, 2017</li>
<li>ENAS：H. Pham, M. Y. Guan, B. Zoph, Q. V. Le, and J. Dean. Efficient neural architecture search via parameter sharing. arXiv:1802.03268, 2018.</li>
<li>Style Transfer: J. Johnson, A. Alahi, and L. Fei-Fei. Perceptual losses for real-time style transfer and super-resolution. arXiv:1603.08155, 2016</li>
</ol>

      </div>
      
      
    </body>
    
    
    
    
    
    
    
  </html>
