from core import baseline, se_densenet, se_densenet_full, densenet_w_block_ce_1_1_res_e_trans_resInce_pool2_2M_Nres_Crop_YXY, densenet_w_block_ce_1_1_Crop_YXY, densenet_w_block_ce_1_1_resInce_pool2_2M_Nres_YXY, densenet_w_block_ce_pool2_2M_Nres_YXY, se_densenet_w_block56
from core import densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_B, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool2_2M_Nres_Crop_YXY_A, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool2_2M_Nres_Crop_YXY_B, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_C, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_D, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_E, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_F
from core import densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_DA, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_G, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_H, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_I, densenet_w_block_ce_1_1_InceA1_e_trans_resInce_2_2pool_Nres_Crop_YXYA, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool2_2M_Nres_Crop_YXYC, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool2_2M_Nres_Crop_56_56_YXY, densenet_w_block56
from core import densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_J, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInceno_pool_Nres_Crop_YXY_B, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_K, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_L, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_M, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_N, densenet_w_block_ce_1_1_InceA1_e_trans_resInce_2_2pool_Nres_Crop_YXY, densenet_w_block_ce_1_1_InceA2_e_trans_resInce_Nres_Crop_YXY
from core import se_densenet_w_block_b_Inception, se_densenet_w_block_c_Inception_YXY, se_densenet_w_block_ab, se_densenet_w_block_ac, se_densenet_w_block_d_residual, se_densenet_w_block_e_residual_YXY, se_densenet_w_block_f_LeakyReLU, se_densenet_w_block_acegh, se_densenet_w_block_g_dynamicReLU_YXY, se_densenet_w_block_h_SN_Switchable_N, se_densenet_w_block_acegh_a, se_densenet_w_block_ce, se_densenet_w_block_c56_Inception_YXY, se_densenet_w_block_ce56_Inception_res_YXY, se_densenet_w_block_ce56_Inception_3_3_res_YXY
from core import densenet_ce56_Inception_3_3_res_YXY, densenet_w_block_ce_3_3_res_InceA1_YXY, densenet_w_block_ce_1_1_res_Crop_trans_Ince_YXY, se_efficient_densenet, se_densenet_w_block_a, se_densenet_w_block_a_n_1__1_nconv, densenet_ce56_Inception_3_3_res_onlyconv_YXY, densenet_w_block_ce_3_3_res, densenet_w_block, densenet_w_block_ce_1_1_res, densenet_w_block_ce_1_1_res_InceA1_YXY, densenet_w_block_ce_1_1_res_InceA1_n1_1n_YXY, densenet_w_block_ce_1_1_res_InceA2_a_YXY, densenet_w_block_ce_1_1_res_InceA1_trans_Ince_YXY
from core import densenet_w_block_ce_1_1_res_Crop_Pool_trans_Ince_YXY, densenet_w_block_ce_1_1_res_InceA2_b_YXY, densenet_w_block_ce_1_1_res_InceA1_trans_Ince_a_YXY, densenet_w_block_ce_1_1_res_InceA2_c_YXY, densenet_w_block_ce_1_1_res_InceA2_stride2_3113_YXY, densenet_w_block_ce_1_1_res_InceA1_trans_Ince_b_YXY, densenet_w_block_ce_1_1_res_InceA1a_YXY, densenet_w_block_ce_1_1_res_InceA1b_YXY, densenet_w_block_ce_1_1_res_InceA2_d_YXY, densenet_w_block_ce_1_1_res_InceA1_trans_Ince_c_YXY, densenet_w_block_ce_1_1_InceA2_e_trans_resInce_Nres_Crop_YXYA
from core import se_densenet_full_in_loop, se_densenet_w_block, densenet_w_block_ce_1_1_res_InceA2_e_YXY, densenet_w_block_ce_1_1_res_InceA1c_YXY, densenet_w_block_ce_1_1_res_InceA1_trans_Ince_d_YXY, densenet_w_block_ce_1_1_res_InceA2_e_trans_Ince_YXY, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_Crop_YXY, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_Crop_bujia_YXY, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_Crop_bujia_cancha_YXY, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_Crop_bujia_cancha_denseblock_also_YXY
from core import densenet_w_block_e_residual_YXY, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_Crop_yuReLU_YXY, densenet_w_block_e_new_residual_YXY, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Crop_YXY, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY, densenet_w_block_ce_1_1_res_InceA2_e_trans_Ince_pool_Nres_Crop_YXY, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nrespool_Crop_YXY, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInceV3_pool_Nres_Crop_YXY, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_A
from core import densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_YXY, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool2_2_Nres_Crop_YXY, densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool2_2M_Nres_Crop_YXY,densenet_w_block_ce_1_1_res_InceA2_e_trans_resInceno_pool_Nres_Crop_YXY_A
from core2 import se_densenet_base, se_densenet_DWSC, SAse_densenet_DWSC, se_densenet_base_YXY, SA2_4_se_densenet, SA1_SA2_4_se_densenet, SE_SA2_4_se_densenet, SA2_4_se_densenet_A, SA2_4_se_densenet_B, SE_SA2_4_se_densenet_B, SE_SA2_4_se_densenet_C, SE_SA2_4_se_densenet_D, se_densenet_ACB_YXY, se_FCA_YXY, se_CA, se_CA_FCA, se_conv_CAM, se_conv_CAM_FCA, se_CASE, se_CA_SE, se_CA_SE_S, se_CA_S_FCA, SE_SA2_4_se_densenet01, SE_SA2_4_se_densenet10, SE_SA2_4_se_densenet11
from core2 import densenet_hash, densenet_CA, densenet_CBAM, densenet_CBAM2, densenet_PSA, densenet_PSA_CA, densenet_Res2Net, densenet_PSA_A, densenet_ViT, densenet_ViTA, densenet_ResNext, densenet_ResNext_PSA, densenet_ResNext_PSAA, densenet_ResNext_PSAB, densenet_ResNext_PSAC, densenet_ResNext_PSAD, densenet_ResNext_PSAE, densenet_ResNext_PSAF, densenet_ResNext_PSAH, densenet_ResNext_PSAG, densenet_ResNext_PSAI, densenet_MHSA
from core2 import densenet_ResNext_PSAJ, densenet_ResNext_PSAK, densenet_ResNext_PSAL, densenet_ResNext_PSAM, densenet_ResNext_PSAN, densenet_ResNext_PSAO, densenet_ResNext_PSAP, densenet_ResNext_PSAQ, densenet_ResNext_PSAR, densenet_Res2Net_PSAA, densenet_Res2Net_PSAB, densenet_ResNext_PSAS, densenet_ResNext_PSAT, densenet_ResNext_PSAU, densenet_ResNext_PSAV, densenet_ResNext_PSAW, densenet_ResNext_PSAX
from core3 import resnet, densenet_Group1X1_4, densenet_DWSC, densenet_Group, densenet_resblock, densenet_Group_PSA, \
    densenet_PSA_4488, densenet_Group_PSA_All8, densenet_Group_NPSA, densenet_Group_35, densenet_ACB, densenet_ACB_35, \
    densenet_GroupA, densenet_ACB_3_5, densenet_ACB_3_5_VIT, densenet_ACB_3_5_VIT_Ares, densenet_ACB_3_5_VIT_res, \
    densenet_ACB_3_5_res, densenet_ACBG, densenet_3_5, densenet_LACB, densenet_MHSA_G, densenet_ACB_VIT_G, \
    densenet_ACB_VIT_res_G, densenet_ACB_VIT_G_SC, densenet_ACB_VIT_G_TBC, densenet_ACB_VIT_G_TBCA, \
    densenet_ACB_VIT_G_TBCB, Trans_TBC_Cond, Trans_down, Trans_Diret, Trans_dense, Trans_den, Trans_dend, Trans_dens2, \
    Trans_dend_g, Trans_dend_TBC, Trans_dend_TBC_Cond, Trans_dend_TBC_Cond1, Trans_dend_TBC_CondT, Trans_dend_TBC_Cond2, \
    Trans_dend_TBC_Cond3
from core3 import densenet_ACB_VIT_GA, densenet_ACB_VIT_GB, densenet_ACB_VIT_G_TBCC, densenet_ACB_VIT_G_TBCT, densenet_ACB_VIT_G_TBCTA, Trans_TBC
from core4 import densenetVit_XCA, denVit, denVit_Sim, denVit_GAM, denVit_NAM, denVit_SiGA, denVit_SiNA, den_SiGA, den_SiNA, den_Sim, den_GAM, den_NAM
import core
import core3
import core5

import models_32
import models_32.model_YXY.alexnet
import model_DualT.model_YXY_google2_11.model_YXY_Google
import model_DualT.model_YXY_google2_11.model_YXY_Google.googlenet_YXY
import model_DualT.model_YXY_google2_11.model_YXY_ZFNet_14
import models_32.model_YXY_se_resnet



def get_model(model_index=0, weight_path=None, Config = None, num_classes=1000):
# def get_model(model_index=0, weight_path=None, Config = None):
# def get_model(model_index=0, weight_path=None):
    print("获取神经网络模型")
    # 不能使用迁移学习，因为1000类的预训练模型，我们的数据集是2分类         #但是发现修改了后面训练的优化参数、回传参数就可以完成了
    # 已经编写完成直接训练的
    # 下面的有（pretrained=False）的代码都是没法使用迁移学习的代码，能使用迁移学习也需要对代码进行重新编写
    if model_index == 0:
        # model = alexnet()
        # print(summary(model, (3, 224, 224)))
        # return bulid_model_YXY.alexnet()
        # return models_32.vision.alexnet(num_classes=2)
        return models_32.vision.alexnet(num_classes=num_classes)
    # 如果使用预训练的还是不行，因为尺寸还是不行， size mismatch for classifier.6.bias: copying a param with shape torch.Size([1000]) from checkpoint, the shape in current model is torch.Size([2])
    elif model_index == 111:
        return models_32.vision.alexnet(num_classes=2)
    elif model_index == 11199:
        return models_32.vision.alexnet(num_classes=2, pretrained=True)
    elif model_index == 112:
        return models_32.model_YXY.alexnet.alexnet(num_classes=2)     # num_classes写不写无所谓了，因为测试得出结论输入的权重和最后测试的无区别
    elif model_index == 113:
        return models_32.model_YXY.alexnet.alexnet(num_classes=2, pretrained=True)
    # 换成下面这个就可以训练，但由于是1000类，出现了2类会准确率一直都是50%的情况
    elif model_index == 114:
        return models_32.model_YXY.alexnet.alexnet(num_classes=1000, pretrained=True)

    elif model_index == 4801:         #     是40553
        from core.den_ince_crop import se_densenet121
        return se_densenet121(drop_rate=0.2)
    elif model_index == 4802:         #     基于40553,减少密集块层数
        from core.den_ince_crop_S import se_densenet121
        return se_densenet121(drop_rate=0.2)
    elif model_index == 4803:         #     基于40553，减少Inception
        from core.den_inceS_crop import se_densenet121
        return se_densenet121(drop_rate=0.2)
    elif model_index == 4804:         #     基于40553，减少密集块层数, 减少Inception
        from core.den_inceS_crop_S import se_densenet121
        return se_densenet121(drop_rate=0.2)
    elif model_index == 4805:         #     基于40553，减少密集块层数, 减少Inception
        from core.den_inceS_crop_SA import se_densenet121
        return se_densenet121(drop_rate=0.2)
    elif model_index == 4806:         #     基于40553，减少密集块层数, 减少Inception       解决运行很慢的问题        通过crop减半，直接5MB
        from core.den_inceS_crop_SB import se_densenet121
        return se_densenet121(drop_rate=0.2)
    elif model_index == 4807:         #     基于40553，减少密集块层数, 减少Inception       解决运行很慢的问题        但是效果不好
        from core.cropS_S_trans import se_densenet121
        return se_densenet121(drop_rate=0.2)
    elif model_index == 4808:         #     基于40553，减少密集块层数, 减少Inception       解决运行很慢的问题
        from core.cropS_S_trans_D import se_densenet121
        return se_densenet121(drop_rate=0.2)
    elif model_index == 4809:         #     基于40553，减少密集块层数, 减少Inception       解决运行很慢的问题
        from core.cropS_S_trans_DA import se_densenet121
        return se_densenet121(drop_rate=0.2)

    elif model_index == 4810:         #     使用4410的架构对4807改写
        from core4.Crop_MHSA import se_densenet121
        return se_densenet121(drop_rate=0.2)
    elif model_index == 4811:         #     使用4410的架构对4809改写
        from core4.Crop_MHSAA import se_densenet121
        return se_densenet121(drop_rate=0.2)
    elif model_index == 4812:         #     对4811，不进行分2边，直接分开计算再合并      把通道数减半
        from core4.Crop_MHSAB import se_densenet121
        return se_densenet121(drop_rate=0.2)
    elif model_index == 4813:         #     对4811，只保留MHSA
        from core4.Crop_MHSAC import se_densenet121
        return se_densenet121(drop_rate=0.2)

    elif model_index == 4814:         #     先基于4813     快速找到MLP架构
        from core4.Crop_MLP import se_densenet121
        return se_densenet121(drop_rate=0.2)
    elif model_index == 4815:         #     先基于4813     快速找到MLP架构
        from core4.Crop_MLPA import se_densenet121
        return se_densenet121(drop_rate=0.2)
    elif model_index == 4816:         #     先基于4811     对MLP架构进行双分支     采用8分之一  4分之一       2分之一
        from core4.Crop_MLPB import se_densenet121
        return se_densenet121(drop_rate=0.2)
    elif model_index == 4817:         #     先基于4811     对MLP架构进行双分支 这里采用1X1进行分开     采用8分之一  4分之一       2分之一
        from core4.Crop_MLPC import se_densenet121
        return se_densenet121(drop_rate=0.2)
    elif model_index == 4818:         #     基于4817，采用Conv+BN+ReLU
        from core4.Crop_MLPD import se_densenet121
        return se_densenet121(drop_rate=0.2)
    elif model_index == 4819:         #    基于4817，采用BN+。。。
        from core4.Crop_MLPE import se_densenet121
        return se_densenet121(drop_rate=0.2)



    elif model_index == 4601:
        return densenetVit_XCA.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4602:
        return denVit.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4603:
        return denVit_Sim.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4604:
        return denVit_GAM.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4605:
        return denVit_NAM.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4606:
        return denVit_SiGA.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4607:
        return denVit_SiNA.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4608:       # 0.5
        return den_SiGA.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4609:
        return den_SiNA.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4610:
        return den_Sim.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4611:
        return den_GAM.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4612:
        return den_NAM.se_densenet121(num_classes=num_classes, drop_rate=0.2)

    elif model_index == 23403:
        return core3.resnet.resnet18(num_classes=num_classes)



    elif model_index == 4701:
        from core5.repchoice import repchoice
        return repchoice(model='repvgg')
    elif model_index == 4702:
        from core5.repchoice import repchoice
        return repchoice(model='DBB_VGG')
    elif model_index == 4703:
        from core5.repchoice import repchoice
        return repchoice(model='OREPA_VGG')
    elif model_index == 4704:
        from core5.repchoice import repchoice
        return repchoice(model='DBB_Res18')
    elif model_index == 4705:
        from core5.repchoice import repchoice
        return repchoice(model='OREPA_Res18')


    elif model_index == 4710:           #
        from core5.repdensenet import repchoice
        return repchoice(model='OREPA_den')
    elif model_index == 4711:
        from core5.densenet_2C_B_R import se_densenet121
        return se_densenet121(num_classes=2)
        # return repchoice(model='OREPA_den')
    elif model_index == 4712:               # 4711和4712都是对DenseNet稍微变换，效果都还是不错
        from core5.densenet_1C_B_R import se_densenet121
        return se_densenet121(num_classes=2)
    elif model_index == 4713:           # 将错误代码修改准确，nonlinear=nn.ReLU(inplace=True))，但是base效果不太好，DBB倒是不错
        from core5.repdensenet import repchoice
        return repchoice(model='DBB_den_A')
    elif model_index == 4714:           # 再测试orep
        from core5.repdensenet import repchoice
        return repchoice(model='OREPA_den_A')




    elif model_index == 4720:
        from core5.repdenNAT import repchoice
        return repchoice(model='OREPA_denNAT')
    elif model_index == 4721:
        from core5.repdenNAT import repchoice
        return repchoice(model='OREPA_den2res')
    elif model_index == 4725:
        from core5.repdenNAT import repchoice
        return repchoice(model='OREPA_den2den')
    elif model_index == 4730:       # res2net里面4个全部卷积
        from core5.repdenNAT import repchoice
        return repchoice(model='OREPA_den2OCA')
    elif model_index == 4731:       # res2net里面3个进行卷积
        from core5.repdenNAT import repchoice
        return repchoice(model='OREPA_denre2OCA')
    elif model_index == 4732:       # res2net里面3个进行卷积，去掉残差连接
        from core5.repdenNAT import repchoice
        return repchoice(model='OREPA_2denOCA')
    elif model_index == 4733:       # res2net里面4个全部进行卷积，去掉残差连接
        from core5.repdenNAT import repchoice
        return repchoice(model='OREPA_den2SOCA')

    elif model_index == 4734:       # res2net里面4个全部卷积
        from core5.repdenNAT import repchoice
        return repchoice(model='LOREPA_den2OCA')
    elif model_index == 4735:       # res2net里面3个进行卷积
        from core5.repdenNAT import repchoice
        return repchoice(model='LOREPA_denre2OCA')
    elif model_index == 4736:       # res2net里面3个进行卷积，去掉残差连接
        from core5.repdenNAT import repchoice
        return repchoice(model='LOREPA_2denOCA')
    elif model_index == 4737:       # res2net里面4个全部进行卷积，去掉残差连接
        from core5.repdenNAT import repchoice
        return repchoice(model='LOREPA_den2SOCA')

    # “F” 是添加normLN
    elif model_index == 4738:       # res2net里面4个全部卷积
        from core5.repdenNAT import repchoice
        return repchoice(model='FOREPA_den2OCA')
    elif model_index == 4739:       # res2net里面3个进行卷积
        from core5.repdenNAT import repchoice
        return repchoice(model='FOREPA_denre2OCA')
    elif model_index == 4740:       # res2net里面3个进行卷积，去掉残差连接
        from core5.repdenNAT import repchoice
        return repchoice(model='FOREPA_2denOCA')
    elif model_index == 4741:       # res2net里面4个全部进行卷积，去掉残差连接
        from core5.repdenNAT import repchoice
        return repchoice(model='FOREPA_den2SOCA')

    elif model_index == 4742:       # res2net里面4个全部进行卷积，去掉残差连接,去掉MLP
        from core5.repdenNAT import repchoice
        return repchoice(model='FOREPA_den2SOCA_MLP')
    elif model_index == 4743:       # res2net里面4个全部进行卷积，去掉残差连接,去掉MLP,再添加LN
        from core5.repdenNAT import repchoice
        return repchoice(model='FOREPA_den2SOCA_MLPL')

    elif model_index == 47211:       # res2net里面3个进行卷积，去掉残差连接，在4721的基础上添加Shuffle
        from core5.repdenNAT import repchoice
        return repchoice(model='OREPA_den2res1')


    elif model_index == 4790:
        from core5.denseNAT import se_densenet121
        return se_densenet121()





    elif model_index == 9802:           # ([16, 1008, 7, 7])
        from core5.regnetLFZ import regnetx_032
        return regnetx_032()
    elif model_index == 9803:           # ([16, 1008, 7, 7])
        from core5.repmodels.regnet_b import regnetx_032
        return regnetx_032()
    elif model_index == 9804:
        from core5.repreg import repchoice
        return repchoice(model='OREPA_reg')
    elif model_index == 9805:              # 和densenet一样的架构
        from core5.repreg import repchoice
        return repchoice(model='OREPA_reg2OCA')
    elif model_index == 9806:
        from core5.repreg import repchoice
        return repchoice(model='OREPA_regNAT')
    # elif model_index == 9807:           # ([16, 1008, 7, 7])
    #     from coreA.regnetLFZ import regnetx_032
    #     return regnetx_032()
    # elif model_index == 9808:
    #     from coreA.repreg import repchoice
    #     return repchoice(model='OREPA_reg')
    # elif model_index == 9809:
    #     from coreA.repreg import repchoice
    #     return repchoice(model='OREPA_reg2OCA')
    elif model_index == 9810:
        from core5.repreg import repchoice
        return repchoice(model='OREPA_regENAT')



    elif model_index == 151:
        print("选择了ZFNet1")  #不能运行
        return model_DualT.model_YXY_google2_11.model_YXY_ZFNet_14.ZFNet1(class_count=256)

    elif model_index == 155:
        print("选择了ZFNet2")  #能运行    默认是number_of_classes=100，被我修改为2分类了，直接在网络层面进行的修改
        return model_DualT.model_YXY_google2_11.model_YXY_ZFNet_14.ZFNet2()
    # 但是做ZFNet可视化的时候，没法把每一层对图像处理的特征图取出来


    #   暂时这里的工作准备围绕着新的创新点做，1添加空间可分离卷积和SE        2实现CA注意力机制      3实现多标签分类
    # elif model_index == 4110:
    #     return se_densenet_w_block.se_densenet121(drop_rate=0.2)
    # 看看后续是否需要考虑注意力机制的位置放到哪，也就是怎么配置
    elif model_index == 4201:       # 来自于这篇文章的https://ieeexplore.ieee.org/document/9107210/references#references密集块和最后预测块后添加SEblock。最终还是只在密集单元前面放一个SEblock
        return se_densenet_base.se_densenet121(drop_rate=0.2)
    elif model_index == 4202:
        return se_densenet_DWSC.se_densenet121(drop_rate=0.2)
    elif model_index == 4203:
        return SAse_densenet_DWSC.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4204:
        return se_densenet_base_YXY.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4205:
        return SA2_4_se_densenet.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4206:
        return SA1_SA2_4_se_densenet.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4207:
        return SE_SA2_4_se_densenet.se_densenet121(drop_rate=0.2)
    elif model_index == 4208:
        return SA2_4_se_densenet_A.se_densenet121(drop_rate=0.2)
    elif model_index == 4209:               # 改进于4205，但这里是把密集块输出作门控
        return SA2_4_se_densenet_B.se_densenet121(drop_rate=0.2)
    elif model_index == 4210:               # 改进于4205，但这里是把密集块输出作门控
        return SE_SA2_4_se_densenet_B.se_densenet121(drop_rate=0.2)
    elif model_index == 4211:       # 来自于这篇文章的https://ieeexplore.ieee.org/document/9107210/references#references密集块和最后预测块后添加SEblock。最终还是只在密集单元前面放一个SEblock
        return se_densenet_base.se_densenet121(num_classes=15, drop_rate=0.2)
    elif model_index == 4212:
        return se_densenet_DWSC.se_densenet121(num_classes=15, drop_rate=0.2)
    elif model_index == 4213:
        return SAse_densenet_DWSC.se_densenet121(num_classes=15, drop_rate=0.2)
    elif model_index == 4214:
        return se_densenet_base_YXY.se_densenet121(num_classes=15, drop_rate=0.2)
    elif model_index == 4215:
        return SE_SA2_4_se_densenet_C.se_densenet121(drop_rate=0.2)
    elif model_index == 4216:       # 将DenseNet的参数缩小。缩小一半。但没成功
        return SE_SA2_4_se_densenet_D.se_densenet121(drop_rate=0.2)
    elif model_index == 4217:
        return SE_SA2_4_se_densenet01.se_densenet121(drop_rate=0.2)
    elif model_index == 4218:
        return SE_SA2_4_se_densenet10.se_densenet121(drop_rate=0.2)
    elif model_index == 4219:
        return SE_SA2_4_se_densenet11.se_densenet121(drop_rate=0.2)


    elif model_index == 4220:
        return se_densenet_ACB_YXY.se_densenet121(drop_rate=0.2)

    elif model_index == 4224:               # 基于4204
        return se_FCA_YXY.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4225:               # 基于4204
        return se_CA.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4226:               # 基于4204
        return se_CA_FCA.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4227:               # 基于4204，需要测试
        return se_conv_CAM.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4228:               # 基于4204，需要测试
        return se_conv_CAM_FCA.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4229:               # 基于4225        参数量特别大，不使用
        return se_CASE.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4230:               # 基于4225
        return se_CA_SE.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4231:               # 基于4230        这个参数量比4230小很多，比SE大一点点
        return se_CA_SE_S.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4232:               # 基于4231            这个效果不好
        return se_CA_S_FCA.se_densenet121(num_classes=num_classes, drop_rate=0.2)


    elif model_index == 4240:               # 基于4023
        from core5.densenet_base import se_densenet121
        return se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4241:               # 基于4023
        from core5.densenet_base_YXY_ECA import se_densenet121
        return se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4242:               # 基于4023
        from core5.densenet_base_YXY_SRM import se_densenet121
        return se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4243:               # 基于4023
        from core5.densenet_base_YXY_SE import se_densenet121
        return se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4244:               # 基于4023
        from core5.densenet_base_YXY_GCT import se_densenet121
        return se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 4245:               # 基于4023
        from core5.densenet_base_YXY_CA import se_densenet121
        return se_densenet121(num_classes=num_classes, drop_rate=0.2)




    elif model_index == 4301:
        return densenet_hash.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4302:
        return densenet_CA.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4303:
        return densenet_CBAM.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4304:
        return densenet_CBAM2.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4305:
        return densenet_PSA.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4306:
        return densenet_PSA_A.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4307:
        return densenet_PSA_CA.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4308:
        return densenet_Res2Net.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4309:       # 使用4302改的，删除了CA
        return densenet_ViT.se_densenet121(num_classes=2, drop_rate=0.2)
    # 4309 出现BN问题，因此删除，改4310.具体问题:    if input.dim() != 4:    # AttributeError: 'NoneType' object has no attribute 'dim'
    elif model_index == 4310:       # 使用4303改的, 而且CBAM没有删除
        return densenet_ViTA.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4311:     # 加残差模型是densenet_ResNext_Res
        return densenet_ResNext.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4312:
        return densenet_ResNext_PSA.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4313:
        return densenet_ResNext_PSAA.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4314:
        return densenet_ResNext_PSAB.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4315:
        return densenet_ResNext_PSAC.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4316:       # PSA卷积采用3X3,5X5        加残差
        return densenet_ResNext_PSAD.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4317:       # PSA卷积采用1X1,3X3       加残差
        return densenet_ResNext_PSAE.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4318:       # PSA卷积采用1X1,3X3       修改残差，采用conv后续还加bn+relu，bn以后再残差相加
        return densenet_ResNext_PSAF.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4319:       # PSA卷积采用1X1,3X3       修改残差，将结构全改为conv+Bn+reLu
        return densenet_ResNext_PSAG.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4320:       # PSA卷积采用1X1,3X3       修改残差，将结构全改为conv+Bn+reLu      再将PSA的SE除掉
        return densenet_ResNext_PSAH.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4321:       # PSA卷积采用1X1,3X3       修改残差，将结构全改为conv+Bn+reLu      再将PSA的SE除掉,放残差之前
        return densenet_ResNext_PSAI.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4322:       # PSA卷积采用1X1,3X3       修改残差，将结构全改为conv+Bn+reLu      再将PSA的SE除掉,放残差之前        去掉残差
        return densenet_ResNext_PSAJ.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4323:       # PSA卷积采用1X1,3X3       修改残差，将结构全改为conv+Bn+reLu      再将PSA的SE除掉,放残差之前        基于4321  SE改残差之后
        return densenet_ResNext_PSAK.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4324:       # 基于4320，将BN由残差前改为残差后-
        return densenet_ResNext_PSAL.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4325:       # PSA卷积采用1X1,3X3       修改残差，将结构全改为conv+Bn+reLu      基于4323  SE改残差之后     将前面4个块切开改为不切开
        return densenet_ResNext_PSAM.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4326:       # PSA卷积采用1X1,3X3       修改残差，将结构全改为conv+Bn+reLu      基于4325  SE改残差之后     将前面4个块切开改为不切开     四个快bn后加一起
        return densenet_ResNext_PSAN.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4327:       # PSA卷积采用1X1,3X3       修改残差，将结构全改为conv+Bn+reLu      基于4325  SE改残差之后     将前面4个块切开改为不切开     四个快bn后加一起      去掉最后的残差链接
        return densenet_ResNext_PSAO.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4328:       # PSA卷积采用1X1,3X3       修改残差，将结构全改为conv+Bn+reLu      基于4323  SE改残差之后     将前面4个块切开改为不切开     并使用ys1对ys2残差链接
        return densenet_ResNext_PSAP.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4329:       # PSA卷积采用1X1,3X3       修改残差，将结构全改为conv+Bn+reLu      基于4327  去掉最后的残差链接
        return densenet_ResNext_PSAQ.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4330:       # PSA卷积采用1X1,3X3       修改残差，将结构全改为conv+Bn+reLu      基于4328  并使用ys1对ys2残差链接      去掉最后的残差链接
        return densenet_ResNext_PSAR.se_densenet121(num_classes=2, drop_rate=0.2)

    elif model_index == 4331:       # 基于4323    加残差
        return densenet_Res2Net_PSAA.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4332:       # 基于4323       不加残差
        return densenet_Res2Net_PSAB.se_densenet121(num_classes=2, drop_rate=0.2)


    elif model_index == 4341:       # PSA卷积采用3X3  5X5     修改残差，将结构全改为conv+Bn+reLu      基于4328  SE改残差之后     将前面4个块切开改为不切开     并使用ys1对ys2残差链接
        return densenet_ResNext_PSAS.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4342:       # PSA卷积采用3X3  5X5        修改残差，将结构全改为conv+Bn+reLu      基于4330  SE改残差之后     将前面4个块切开改为不切开     并使用ys1对ys2残差链接      去掉最后的残差链接
        return densenet_ResNext_PSAT.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4343:       # PSA卷积采用3X3  5X5        修改残差，将结构全改为conv+Bn+reLu      基于4342  SE改残差之后     将前面4个块切开改为不切开     并使用ys1对ys2残差链接      去掉最后的残差链接     并将newfeaturemap也和他们残差连接在一起
        return densenet_ResNext_PSAU.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4344:       # 基于4323   PSA卷积采用5X5,3X3       修改残差，将结构全改为conv+Bn+reLu      再将PSA的SE除掉       SE改残差之后
        return densenet_ResNext_PSAV.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4345:       # 基于4323   PSA卷积采用5X5,3X3       修改残差，将结构全改为conv+Bn+reLu      再将PSA的SE除掉       SE改残差之后       去掉残差
        return densenet_ResNext_PSAW.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4346:       # 基于4323   PSA卷积采用5X5,3X3       修改残差，将结构全改为conv+Bn+reLu      再将PSA的SE除掉       SE改残差之后       去掉残差     并将newfeaturemap也和他们残差连接在一起
        return densenet_ResNext_PSAX.se_densenet121(num_classes=2, drop_rate=0.2)




    elif model_index == 4401:       # 基于4203改   最后一个模块换为transformer
        return densenet_MHSA.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4402:       # 基于4023改       1X1改为分组卷积4      参数量47.96
        return densenet_Group1X1_4.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4403:       # 基于4203改       DWSC    参数量59.59    59.59
        return densenet_DWSC.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4404:       # 基于4023改       DWC    参数量18.01 1X1参数量改为最小
        return densenet_Group.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4405:       # 基于core3/densenet_base_YXY
        return densenet_resblock.se_densenet121(num_classes=2, drop_rate=0.2)
    # 还需要写个密集块外面的残差连接，和PSA
    elif model_index == 4406:       # 基于4305改       参数量48.05
        return densenet_PSA_4488.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4407:       # 基于4305和4404改       参数量12.99
        return densenet_Group_PSA.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4408:       # 基于4305和4404改       All8参数量11.06       All8_1357参数量6.53
        return densenet_Group_PSA_All8.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4409:       # 基于4408改       All8_1357    去掉SE,参数量6.46      并加在后面      参数量6.53   和4408参数量一样
        return densenet_Group_NPSA.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4410:       # 基于4409改       All16_35   参数量3.70
        return densenet_Group_35.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4411:       # 基于core3/densenet_base_YXY     #参数量64MB    #分组卷积为32后 参数量37.69
        return densenet_ACB.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4412:       # 基于4410和4411     #Group_PSA_ACB参数量4.69MB
        return densenet_ACB_35.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4413:       # 基于4404     # 将3X3的分组卷积也给到最大        densenet_GroupA参数量2.21MB
        return densenet_GroupA.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4414:       # 基于4412     # 改进ACB为2个ACB串联    参数量3.71MB   251S
        return densenet_ACB_3_5.se_densenet121(num_classes=2, drop_rate=0.2)
        # return densenet_ACB_3_5.se_densenet121(num_classes=2, drop_rate=0.2)      # 修改分组为//4  参数量6.63MB
    # 16 //4 参数量6.63MB 251S           8 //4  参数量8.44MB  256S         4 //4  参数量12.05MB 260S          16 //2 参数量4.68MB 252S
    elif model_index == 4415:       # 基于4411    1X1采用分组卷积后 参数量2.64MB
        return densenet_ACBG.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4416:       # 基于4412     # 改进ACB为2个ACB串联  而且直接劈开特征图       参数量6.63MB   251S  修改为//4
        return densenet_3_5.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4417:       # 基于4411      #分组卷积为32后,且1*1卷积修改为//4 参数量5.56MB  时间226S，也挺长的
        return densenet_LACB.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4418:       # 基于4412           # 添加4401的VIT     参数量28.98MB
        return densenet_ACB_3_5_VIT.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4419:       # 基于4415           # 添加4405的残差     参数量54.68MB
        return densenet_ACB_3_5_VIT_Ares.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4420:       # 基于4416           # 将残差最后的VIT模块的删除     参数量50.68MB
        return densenet_ACB_3_5_VIT_res.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4421:       # 基于4412     # 添加4405的残差    参数量
        return densenet_ACB_3_5_res.se_densenet121(num_classes=2, drop_rate=0.2)

    # 自校准卷积     https://mp.weixin.qq.com/s/wTmhlTo4oFIdNxXNK5spMg   这个暂时用不上没进行实现
    elif model_index == 4431:       # 基于4418           # 基于4503，在ACB和MHSA基础上添加
        return densenet_ACB_VIT_G_SC.se_densenet121(num_classes=2, drop_rate=0.2)
    # 3交叉中心差分卷积     https://mp.weixin.qq.com/s/VqAAOWWiR8yqthOUWh5TqA
    elif model_index == 4432:       # 基于4418           # 基于4503，在ACB和MHSA基础上添加TBC
        return densenet_ACB_VIT_G_TBC.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4433:       # 基于4432           # 在ACB和MHSA基础上添加ACB到整个网络
        return densenet_ACB_VIT_G_TBCA.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4434:       # 基于4432           # 在ACB和MHSA基础上，将K的数据改为三分路11,13,31        这里基于TBC
        return densenet_ACB_VIT_G_TBCB.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4435:       # 基于4503           # 在ACB和MHSA基础上，将K的数据改为三分路11,13,31
        return densenet_ACB_VIT_GA.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4436:       # 基于4435           # 在ACB和MHSA基础上，将K的数据改为三分路11,13,31        去掉BN
        return densenet_ACB_VIT_GB.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4437:       # 基于4432           # 将——DenseblockD的第一个1X1改为ACB
        return densenet_ACB_VIT_G_TBCC.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4438:       # 基于4432           # 在MHSA中，将K的数据改为三分路11,13,31
        return densenet_ACB_VIT_G_TBCT.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4439:       # 基于4432           # 在MHSA中，将K的数据改为三分路11,13,31      这里采用自己手写
        return densenet_ACB_VIT_G_TBCTA.se_densenet121(num_classes=2, drop_rate=0.2)


    elif model_index == 4501:       # 基于4401
        return densenet_MHSA.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4502:       # 基于4501
        return densenet_MHSA_G.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4503:       # 基于4418
        return densenet_ACB_VIT_G.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4504:       # 基于4420
        return densenet_ACB_VIT_res_G.se_densenet121(num_classes=2, drop_rate=0.2)


    elif model_index == 4440:       # 基于4432           # 在MHSA中，将K的数据改为三分路11,13,31      这里采用自己手写
        return Trans_TBC.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4441:       # Cond_TBC
        return Trans_TBC_Cond.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4442:       # Transformer 下采样
        return Trans_down.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4443:
        return Trans_Diret.se_densenet121(num_classes=2, drop_rate=0.2)

    elif model_index == 4445:       # A DenseNet
        return Trans_dense.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4446:       # Transformer
        return Trans_den.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4447:       #  Transformer s=2
        return Trans_dens2.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4448:       # 方向Transformer
        return Trans_dend.se_densenet121(num_classes=2, drop_rate=0.2)

    elif model_index == 4449:       # 方向Transformer+分组轻量化
        return Trans_dend_g.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4450:       # 方向Transformer+高效轻量化
        return Trans_dend_TBC.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4451:       # 方向Transformer+高效轻量化
        return Trans_dend_TBC_Cond.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4452:       # 方向Transformer+高效轻量化   1*1
        return Trans_dend_TBC_Cond1.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4453:       # 方向Transformer+高效轻量化   1*1     ALL过渡层
        return Trans_dend_TBC_Cond2.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4454:       # 方向Transformer+高效轻量化   1*1     ALL过渡层+初始层
        return Trans_dend_TBC_Cond3.se_densenet121(num_classes=2, drop_rate=0.2)
    elif model_index == 4455:       # 方向Transformer+高效轻量化   1*1  Trans
        return Trans_dend_TBC_CondT.se_densenet121(num_classes=2, drop_rate=0.2)





    # 不能使用，因为1000类的预训练模型，我们的数据集是2分类,出现的效果为准确率一直为50%
    # 这个VGG的loss和优化器不合适，因此选择暂时换到model_YXY里面的代码去进行运行，train_VGG.py和test_VGG.py
    elif model_index == 11:
        return models_32.vision.vgg11()
    elif model_index == 12:
        return models_32.vision.vgg11_bn()
    elif model_index == 13:
        return models_32.vision.vgg13()
    elif model_index == 14:
        return models_32.vision.vgg13_bn()
    elif model_index == 15:
        return models_32.vision.vgg16()
    elif model_index == 16:
        return models_32.vision.vgg16_bn()
    elif model_index == 17:
        return models_32.vision.vgg19(num_classes=num_classes)
        # return models_32.vision.vgg19()
    elif model_index == 18:
        return models_32.vision.vgg19_bn()
    # 上面的不加载预训练模型通过VGG训练可以实现，原因是对优化参数的调整，使得它的效果达到更好
    # 通过修改学习率之后，使得VGG使用class_nums=1000的权重也可以进行训练，现在回上去测试Alexnet也是可以进行训练的，而且也不再出现50%的情况了
    elif model_index == 121:
        return models_32.vision.vgg11(num_classes=1000, pretrained=True)
    elif model_index == 122:
        return models_32.vision.vgg11_bn(pretrained=True)
    elif model_index == 123:
        return models_32.vision.vgg13(pretrained=True)
    elif model_index == 124:
        return models_32.vision.vgg13_bn(pretrained=True)
    elif model_index == 125:
        return models_32.vision.vgg16(pretrained=True)
    elif model_index == 126:
        return models_32.vision.vgg16_bn(pretrained=True)
    elif model_index == 127:
        return models_32.vision.vgg19(pretrained=True)
    elif model_index == 128:
        return models_32.vision.vgg19_bn(pretrained=True)

    # repvgg_a2
    elif model_index == 131:                #
        from models_32.model_YXY_fullgood_13.models.byobnet import repvgg_a2
        return repvgg_a2()
    elif model_index == 132:                # 预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.byobnet import repvgg_a2
        return repvgg_a2(pretrained=True)
    elif model_index == 133:
        from models_32.model_YXY_fullgood_13.models.byobnet import repvgg_b0
        return repvgg_b0()
    elif model_index == 134:                #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.byobnet import repvgg_b0
        return repvgg_b0(pretrained=True)
    elif model_index == 135:
        from models_32.model_YXY_fullgood_13.models.byobnet import repvgg_b1
        return repvgg_b1()
    elif model_index == 136:                #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.byobnet import repvgg_b1
        return repvgg_b1(pretrained=True)
    elif model_index == 137:
        from models_32.model_YXY_fullgood_13.models.byobnet import repvgg_b1g4
        return repvgg_b1g4()
    elif model_index == 138:                #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.byobnet import repvgg_b1g4
        return repvgg_b1g4(pretrained=True)
    elif model_index == 139:
        from models_32.model_YXY_fullgood_13.models.byobnet import repvgg_b2
        return repvgg_b2()
    elif model_index == 141:                #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.byobnet import repvgg_b2
        return repvgg_b2(pretrained=True)
    elif model_index == 142:
        from models_32.model_YXY_fullgood_13.models.byobnet import repvgg_b2g4
        return repvgg_b2g4()
    elif model_index == 143:                #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.byobnet import repvgg_b2g4
        return repvgg_b2g4(pretrained=True)
    elif model_index == 144:
        from models_32.model_YXY_fullgood_13.models.byobnet import repvgg_b3g4
        return repvgg_b3g4()
    elif model_index == 145:                #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.byobnet import repvgg_b3g4
        return repvgg_b3g4(pretrained=True)



    # 可以使用，这个不用输入类的数目，默认使用的1000类，但是通过修改最后一层就可以完成num_classes=2的操作
    elif model_index == 21:
        return models_32.vision.resnet18(num_classes=num_classes)
    elif model_index == 22:
        return models_32.vision.resnet34()
    elif model_index == 23:
        return models_32.vision.resnet50()
    elif model_index == 24:
        return models_32.vision.resnet101()
    elif model_index == 25:
        return models_32.vision.resnet152()
    elif model_index == 26:
        return models_32.vision.resnext50_32x4d()
    elif model_index == 27:
        return models_32.vision.resnext101_32x8d()

    # 这个是重新对原始的网络再编写的，可以使用迁移学习完成了,而且对分类的类数可以自己调节
    elif model_index == 221:
        return models_32.Resnet18(pretrained=True)
    elif model_index == 222:
        return models_32.Resnet34(pretrained=True)
    elif model_index == 223:
        return models_32.Resnet50(pretrained=True)
    elif model_index == 224:
        return models_32.Resnet101(pretrained=True)
    elif model_index == 225:
        return models_32.Resnet152(pretrained=True)
    elif model_index == 226:
        return models_32.Resnext101_32x8d(pretrained=True)
    elif model_index == 227:
        return models_32.Resnext101_32x16d(pretrained=True)
    elif model_index == 228:
        return models_32.Resnext101_32x32d(pretrained=True)
    elif model_index == 229:
        return models_32.Resnext101_32x48d(pretrained=True)

    # 这个是不使用迁移学习的调用代码
    elif model_index == 231:
        return models_32.Resnet18(num_classes=num_classes)
    elif model_index == 232:
        return models_32.Resnet34()
    elif model_index == 233:
        return models_32.Resnet50()
    elif model_index == 234:
        return models_32.Resnet101(num_classes=num_classes)
    elif model_index == 23499:
        return models_32.Resnet101(pretrained=True, num_classes=num_classes)
    elif model_index == 23401:
        return models_32.Resnet101_SK(num_classes=num_classes)
    elif model_index == 23402:
        return models_32.Resnet18_SK(num_classes=num_classes)
    elif model_index == 235:
        return models_32.Resnet152()
    elif model_index == 236:
        return models_32.Resnext101_32x8d(num_classes=num_classes)
    elif model_index == 237:
        return models_32.Resnext101_32x16d(num_classes=num_classes)
    elif model_index == 238:
        return models_32.Resnext101_32x32d(num_classes=num_classes)
    elif model_index == 239:
        return models_32.Resnext101_32x48d(num_classes=num_classes)



    elif model_index == 2510:
        from model_YXY_densenet.DyReLU_resnet.src.models.resnet_dy import ResNet50_dy
        return ResNet50_dy()



    elif model_index == 2512:
        from model_YXY_densenet.Switchable_Normalization.imagenet.models.resnet_v1_sn import resnetv1sn18
        return resnetv1sn18()
    elif model_index == 2513:
        from model_YXY_densenet.Switchable_Normalization.imagenet.models.resnet_v1_sn import resnetv1sn34
        return resnetv1sn34()
    elif model_index == 2514:
        from model_YXY_densenet.Switchable_Normalization.imagenet.models.resnet_v1_sn import resnetv1sn50
        return resnetv1sn50()
    elif model_index == 2515:
        from model_YXY_densenet.Switchable_Normalization.imagenet.models.resnet_v1_sn import resnetv1sn101
        return resnetv1sn101()
    elif model_index == 2516:
        from model_YXY_densenet.Switchable_Normalization.imagenet.models.resnet_v1_sn import resnetv1sn152
        return resnetv1sn152()

    elif model_index == 2522:
        from model_YXY_densenet.Switchable_Normalization.imagenet.models.resnet_v2_sn import resnetv2sn18
        return resnetv2sn18()
    elif model_index == 2523:
        from model_YXY_densenet.Switchable_Normalization.imagenet.models.resnet_v2_sn import resnetv2sn34
        return resnetv2sn34()
    elif model_index == 2524:
        from model_YXY_densenet.Switchable_Normalization.imagenet.models.resnet_v2_sn import resnetv2sn50
        return resnetv2sn50()
    elif model_index == 2525:
        from model_YXY_densenet.Switchable_Normalization.imagenet.models.resnet_v2_sn import resnetv2sn101
        return resnetv2sn101()
    elif model_index == 2526:
        from model_YXY_densenet.Switchable_Normalization.imagenet.models.resnet_v2_sn import resnetv2sn152
        return resnetv2sn152()



    # stochastic_depth_resnet
    # 这个模型会出现stochastic_depth_resnet18() got an unexpected keyword argument 'pretrained'        也就是没有定义这个写法
    elif model_index == 240:
        from model_DualT.model_YXY_google2_11.stochasticdepth import stochastic_depth_resnet18
        return stochastic_depth_resnet18(num_classes=2)
    # elif model_index == 241:                #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
    #     from model_DualT.model_YXY_google2_11.stochasticdepth import stochastic_depth_resnet18
    #     return stochastic_depth_resnet18(pretrained=True, num_classes=2)
    elif model_index == 242:
        from model_DualT.model_YXY_google2_11.stochasticdepth import stochastic_depth_resnet34
        return stochastic_depth_resnet34(num_classes=2)
    # elif model_index == 243:                #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
    #     from model_DualT.model_YXY_google2_11.stochasticdepth import stochastic_depth_resnet34
    #     return stochastic_depth_resnet34(pretrained=True, num_classes=2)
    elif model_index == 244:
        from model_DualT.model_YXY_google2_11.stochasticdepth import stochastic_depth_resnet50
        return stochastic_depth_resnet50(num_classes=2)
    # elif model_index == 245:                #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
    #     from model_DualT.model_YXY_google2_11.stochasticdepth import stochastic_depth_resnet50
    #     return stochastic_depth_resnet50(pretrained=True, num_classes=2)
    elif model_index == 246:
        from model_DualT.model_YXY_google2_11.stochasticdepth import stochastic_depth_resnet101
        return stochastic_depth_resnet101(num_classes=2)
    # elif model_index == 247:                #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
    #     from model_DualT.model_YXY_google2_11.stochasticdepth import stochastic_depth_resnet101
    #     return stochastic_depth_resnet101(pretrained=True, num_classes=2)
    elif model_index == 248:
        from model_DualT.model_YXY_google2_11.stochasticdepth import stochastic_depth_resnet152
        return stochastic_depth_resnet152(num_classes=2)
    # elif model_index == 249:                #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
    #     from model_DualT.model_YXY_google2_11.stochasticdepth import stochastic_depth_resnet152
    #     return stochastic_depth_resnet152(pretrained=True, num_classes=2)


    # Table 9: Best WRN performance over various datasets, single run results.
    elif model_index == 251:
        from model_DualT.model_YXY_google2_11.wideresidual import wideresnet
        return wideresnet(num_classes=2)
    # elif model_index == 252:                #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
    #     from model_DualT.model_YXY_google2_11.wideresidual import wideresnet
    #     return wideresnet(pretrained=True, num_classes=2)

    elif model_index == 253:            #不能运行   原因：UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
        # size mismatch, m1: [8 x 1458], m2: [900 x 450] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:273
        from model_DualT.model_YXY_google2_11.rir import resnet_in_resnet
        return resnet_in_resnet(num_classes=2)
    # elif model_index == 254:          #也不能运行      #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
    #     from model_DualT.model_YXY_google2_11.rir import resnet_in_resnet
    #     return resnet_in_resnet(pretrained=True, num_classes=2)



    # PreActResNet其实只是将Conv-BN-ReLU的顺序换了一下，使得存在一条通路从第一个ResNet Block到最后一个ResNet Block，中间不经过非线性变换ReLU，提高模型的准确率。
    elif model_index == 261:
        from model_DualT.model_YXY_google2_11.preactresnet import preactresnet18
        return preactresnet18()
    elif model_index == 262:                #没有找到预训练模型，也就不写预训练的了，但是有fc层可以进行修改
        from model_DualT.model_YXY_google2_11.preactresnet import preactresnet18
        return preactresnet18()
    elif model_index == 263:
        from model_DualT.model_YXY_google2_11.preactresnet import preactresnet34
        return preactresnet34()
    elif model_index == 264:                #没有找到预训练模型，也就不写预训练的了，但是有fc层可以进行修改
        from model_DualT.model_YXY_google2_11.preactresnet import preactresnet34
        return preactresnet34()
    elif model_index == 265:
        from model_DualT.model_YXY_google2_11.preactresnet import preactresnet50
        return preactresnet50()
    elif model_index == 266:                #没有找到预训练模型，也就不写预训练的了，但是有fc层可以进行修改
        from model_DualT.model_YXY_google2_11.preactresnet import preactresnet50
        return preactresnet50()
    elif model_index == 267:
        from model_DualT.model_YXY_google2_11.preactresnet import preactresnet101
        return preactresnet101()
    elif model_index == 268:               #没有找到预训练模型，也就不写预训练的了，但是有fc层可以进行修改
        from model_DualT.model_YXY_google2_11.preactresnet import preactresnet101
        return preactresnet101()
    elif model_index == 269:
        from model_DualT.model_YXY_google2_11.preactresnet import preactresnet152
        return preactresnet152()
    elif model_index == 260:                #没有找到预训练模型，也就不写预训练的了，但是有fc层可以进行修改
        from model_DualT.model_YXY_google2_11.preactresnet import preactresnet152
        return preactresnet152()


    #  GEResNet-Large /GEResNet-Medium/ GEResNet-Small (    问题：AttributeError: module 'torch.jit' has no attribute 'unused'
    # 这是torchvision的版本问题：pip install torchvision==0.4.1     安装新版torch：  https://blog.csdn.net/jacke121/article/details/104783579/   pip install torch===1.4.0 torchvision===0.5.0 -f https://download.pytorch.org/whl/torch_stable.html
    # 必须安装torchvision=0.5.0     已经编写好环境yxy1，对于这个model_YXY_fullgood_13里面的模型都必须要使用yxy1的环境
    elif model_index == 271:                #
        from models_32.model_YXY_fullgood_13.models.byobnet import gernet_l
        return gernet_l()
    elif model_index == 272:                # 预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.byobnet import gernet_l
        return gernet_l(pretrained=True)
    elif model_index == 273:
        from models_32.model_YXY_fullgood_13.models.byobnet import gernet_m
        return gernet_m()
    elif model_index == 274:                #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.byobnet import gernet_m
        return gernet_m(pretrained=True)
    elif model_index == 275:
        from models_32.model_YXY_fullgood_13.models.byobnet import gernet_s
        return gernet_s()
    elif model_index == 276:                #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.byobnet import gernet_s
        return gernet_s(pretrained=True)

    # CSPNet——PyTorch实现CSPDenseNet和CSPResNeXt         / YOLOv4特征提取网络——CSPDarkNet结构解析及PyTorch实现      开源项目YOLOv5相比YOLOv4有了比较夸张的突破，成为了全方位吊打EfficientDet的存在，其特征提取网络也是CSP-DarkNet。
    # torchvision==0.4.1        # cspresnet
    elif model_index == 281:                #
        from models_32.model_YXY_fullgood_13.models.cspnet import cspresnet50
        return cspresnet50()
    elif model_index == 282:                # 预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.cspnet import cspresnet50
        return cspresnet50(pretrained=True)
    elif model_index == 283:
        from models_32.model_YXY_fullgood_13.models.cspnet import cspresnet50d
        return cspresnet50d()
    elif model_index == 284:                #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.cspnet import cspresnet50d
        return cspresnet50d(pretrained=True)
    elif model_index == 285:
        from models_32.model_YXY_fullgood_13.models.cspnet import cspresnet50w
        return cspresnet50w()
    elif model_index == 286:                #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.cspnet import cspresnet50w
        return cspresnet50w(pretrained=True)
    elif model_index == 287:
        from models_32.model_YXY_fullgood_13.models.cspnet import cspresnext50
        return cspresnext50()
    elif model_index == 288:                #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.cspnet import cspresnext50
        return cspresnext50(pretrained=True)
    elif model_index == 289:
        from models_32.model_YXY_fullgood_13.models.cspnet import cspresnext50_iabn
        return cspresnext50_iabn()
    elif model_index == 291:                #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.cspnet import cspresnext50_iabn
        return cspresnext50_iabn(pretrained=True)
    elif model_index == 292:
        from models_32.model_YXY_fullgood_13.models.cspnet import cspdarknet53
        return cspdarknet53()
    elif model_index == 293:                #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.cspnet import cspdarknet53
        return cspdarknet53(pretrained=True)
    elif model_index == 294:
        from models_32.model_YXY_fullgood_13.models.cspnet import cspdarknet53_iabn
        return cspdarknet53_iabn()
    elif model_index == 295:                #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.cspnet import cspdarknet53_iabn
        return cspdarknet53_iabn(pretrained=True)
    #YOLOv4特征提取网络——CSPDarkNet结构解析及PyTorch实现 ，但是也可以用作分类
    elif model_index == 296:
        from models_32.model_YXY_fullgood_13.models.cspnet import darknet53
        return darknet53()
    elif model_index == 297:                #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.cspnet import darknet53
        return darknet53(pretrained=True)


    elif model_index == 299:
        from models_32.model_YXY_fullgood_13.models.dpn import dpn68
        return dpn68()
    elif model_index == 200:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dpn import dpn68
        return dpn68(pretrained=True)
    elif model_index == 201:
        from models_32.model_YXY_fullgood_13.models.dpn import dpn68b
        return dpn68b()
    elif model_index == 202:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dpn import dpn68b
        return dpn68b(pretrained=True)
    elif model_index == 203:
        from models_32.model_YXY_fullgood_13.models.dpn import dpn92
        return dpn92()
    elif model_index == 204:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dpn import dpn92
        return dpn92(pretrained=True)
    elif model_index == 205:
        from models_32.model_YXY_fullgood_13.models.dpn import dpn98
        return dpn98()
    elif model_index == 206:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dpn import dpn98
        return dpn98(pretrained=True)
    elif model_index == 207:
        from models_32.model_YXY_fullgood_13.models.dpn import dpn131
        return dpn131()
    elif model_index == 208:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dpn import dpn131
        return dpn131(pretrained=True)
    elif model_index == 209:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dpn import dpn107
        return dpn107()
    elif model_index == 210:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dpn import dpn107
        return dpn107(pretrained=True)


    # googlenet的31已经预训练的这个是可以训练的,其他的都暂时不能运行     inception_v3需要调整大小为299*299（还有个问题需要解决）
    # 'InceptionOuputs' object has no attribute 'log_softmax'出现在utils_25.py的28 29行没法解决的问题
    elif model_index == 31:
        return models_32.vision.googlenet(pretrained=True)
    # 在这种不使用预训练模型的情况下没法运行，默认不使用权重，问题是上面那个：AttributeError: 'GoogLeNetOuputs' object has no attribute 'log_softmax'
    elif model_index == 32:         #不能使用
        return models_32.vision.googlenet()
    elif model_index == 33:         #不能使用
        return models_32.vision.inception_v3()
    # 等待修改
    elif model_index == 34:            #不能使用
        return models_32.vision.googlenet()
    elif model_index == 35:                #不能使用
        return models_32.vision.inception_v3(pretrained=True)
    #GoogleNet其他网络不能预训练很大程度上是和辅助分类器相关

    elif model_index == 331:       # 'googlenet'    可以使用    这个代码是100类别的
        from model_DualT.model_YXY_google2_11.googlenet import googlenet
        return googlenet(num_class=num_classes)              #这样不使用预训练是可以进行训练的
    elif model_index == 332:       # 'googlenet'       这个不能使用
        from model_DualT.model_YXY_google2_11.googlenet import googlenet
        return googlenet(num_class=2, pretrained=True)       #不能使用，因为预训练了的
    elif model_index == 333:               #'inceptionv3':
        from model_DualT.model_YXY_google2_11.inceptionv3 import inceptionv3
        return inceptionv3(num_classes=2)
    elif model_index == 334:                #不能使用，因为预训练了的
        from model_DualT.model_YXY_google2_11.inceptionv3 import inceptionv3_YXY
        return inceptionv3_YXY(num_classes=2, pretrained=True)
    # 下面这2个模型预训练还没找，以后再说，先这样放着------占用显存太大，batch=4的时候显存都超过了24G，以至于没法判断是否不使用预训练可以正常使用，但是猜测可以使用
    elif model_index == 335:                #'inceptionv4':
        from model_DualT.model_YXY_google2_11.inceptionv4 import inceptionv4
        return inceptionv4(class_nums=2)
    elif model_index == 336:                #'inception_resnet_v2':
        from model_DualT.model_YXY_google2_11.inceptionv4 import inception_resnet_v2
        return inception_resnet_v2(class_nums=2)
    elif model_index == 337:                #'inception_resnet_v2':
        from model_DualT.model_YXY_google2_11.inceptionv4 import inception_resnet_v2
        return inception_resnet_v2(class_nums=2, pretrained=True)

    elif model_index == 338:                #'xception':
        from model_DualT.model_YXY_google2_11.xception import xception
        return xception()
    elif model_index == 339:                #'xception':#这种写法是错误的，但是这个的最后一层是fc层，也就是可以和buildmodel文件一样添加或者是修改最后一层使得classes_num=2
        from model_DualT.model_YXY_google2_11.xception import xception_YXY
        return xception_YXY()
    elif model_index == 340:                #'xception':
        from model_DualT.model_YXY_google2_11.model_YXY_Google.xception import xception
        return xception()


    #     # 可以使用，效果还不错...这里不使用预训练模型，不能进行训练，因为前面这几个基本模型是1000类别的
    # 下面对这里的densenet在1000类别中判断一下准确率，相比于Alexnet和VGG的50%，DenseNet能够在第一个epoch就得到0.8867的训练准确率和0.9600的测试准确率
    elif model_index == 41:
        return models_32.vision.densenet121()
    elif model_index == 42:
        return models_32.vision.densenet161()
    elif model_index == 43:
        return models_32.vision.densenet169()
    elif model_index == 44:
        return models_32.vision.densenet201()
    # 这里的代码是对最后一层的Fc层进行修改，使得最后的代码能完成二分裂
    elif model_index == 441:
        return models_32.Densenet121()
    elif model_index == 442:
        return models_32.Densenet161()
    elif model_index == 443:
        return models_32.Densenet169()
    elif model_index == 444:
        return models_32.Densenet201()

    #    densenet这个预训练过的模型可以运行，前面这4个 451-454训练速度相比如不使用预训练41-44，速度明显更加快
    #   455-458速度区别倒是不大，主要是后面4个是添加了一个fc层
    elif model_index == 451:
        return models_32.vision.densenet121(pretrained=True)
    elif model_index == 452:
        return models_32.vision.densenet161(pretrained=True)
    elif model_index == 453:
        return models_32.vision.densenet169(pretrained=True)
    elif model_index == 454:
        return models_32.vision.densenet201(pretrained=True)
    elif model_index == 455:
        return models_32.Densenet121(pretrained=True)
    elif model_index == 456:
        return models_32.Densenet161(pretrained=True)
    elif model_index == 457:
        return models_32.Densenet169(pretrained=True)
    elif model_index == 458:
        return models_32.Densenet201(pretrained=True)

    # 这些DenseNet是SEDenseNet里面使用的基础的DenseNet，但是都不能运行，出现问题是点乘，和Googlenet出现一样的问题
    # RuntimeError: size mismatch, m1: [16 x 9216], m2: [1024 x 1000] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:273
    #[transforms.Resize((224, 224)),发现是在之前的googlenet那里出现修改图像尺寸导致的尺寸问题；通过transform模块把网络修改好了
    elif model_index == 461:
        return core.baseline.densenet121()
    elif model_index == 462:
        return core.baseline.densenet161()
    elif model_index == 463:
        return core.baseline.densenet169()
    elif model_index == 464:
        return core.baseline.densenet201()
    # 协商预训练就出现问题：   RuntimeError: size mismatch, m1: [16 x 19872], m2: [2208 x 2] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:273
    elif model_index == 465:
        return core.baseline.densenet121(pretrained=True)
    elif model_index == 466:
        return core.baseline.densenet161(pretrained=True)
    elif model_index == 467:
        return core.baseline.densenet169(pretrained=True)
    elif model_index == 468:
        return core.baseline.densenet201(pretrained=True)
    # 最终结论：这个DenseNet原版和上面的DenseNet原版差不多


    elif model_index == 4600:
        from model_YXY_densenet.efficient_densenet_pytorch_master.models.densenet import efficientdensenet
        return efficientdensenet(num_classes = 2)

    # 这个代码也几乎不要
    # se_efficient_densenet
    elif model_index == 420:
        return se_efficient_densenet.DenseNet()
    elif model_index == 421:
        return se_efficient_densenet.densenet121()
    elif model_index == 422:
        return se_efficient_densenet.densenet169()
    elif model_index == 423:
        return se_efficient_densenet.densenet201()
    elif model_index == 424:
        return se_efficient_densenet.densenet161()
    elif model_index == 425:
        return se_efficient_densenet.densenet121(pretrained=True)
    elif model_index == 426:
        return se_efficient_densenet.densenet169(pretrained=True)
    elif model_index == 427:
        return se_efficient_densenet.densenet201(pretrained=True)
    elif model_index == 428:
        return se_efficient_densenet.densenet161(pretrained=True)

    # SEDensenet
    elif model_index == 471:
        return core.se_densenet.se_densenet121()
    elif model_index == 472:
        return core.se_densenet.se_densenet161()
    elif model_index == 473:
        return core.se_densenet.se_densenet169()
    elif model_index == 474:
        return core.se_densenet.se_densenet201()
    # 之前出现这个问题：现在已经修复好了     协商预训练就出现问题：   RuntimeError: size mismatch, m1: [16 x 19872], m2: [2208 x 2] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:273
    elif model_index == 475:
        return core.se_densenet.se_densenet121(pretrained=True)
    elif model_index == 476:
        return core.se_densenet.se_densenet161(pretrained=True)
    elif model_index == 477:
        return core.se_densenet.se_densenet169(pretrained=True)
    elif model_index == 478:
        return core.se_densenet.se_densenet201(pretrained=True)
    # 最终结论：这个DenseNet原版没有上面的DenseNet原版好使用


    # se_densenet_full
    elif model_index == 480:
        return se_densenet_full.SEDenseNet()
    elif model_index == 481:
        return se_densenet_full.se_densenet121()
    elif model_index == 482:
        return se_densenet_full.se_densenet169()
    elif model_index == 483:
        return se_densenet_full.se_densenet201()
    elif model_index == 484:
        return se_densenet_full.se_densenet161()
    elif model_index == 485:
        return se_densenet_full.se_densenet121(pretrained=True)
    elif model_index == 486:
        return se_densenet_full.se_densenet169(pretrained=True)
    elif model_index == 487:
        return se_densenet_full.se_densenet201(pretrained=True)
    elif model_index == 488:
        return se_densenet_full.se_densenet161(pretrained=True)

    # se_densenet_full_in_loop
    elif model_index == 490:
        return se_densenet_full_in_loop.SEDenseNet()
    elif model_index == 491:
        return se_densenet_full_in_loop.se_densenet121()
    elif model_index == 492:
        return se_densenet_full_in_loop.se_densenet169()
    elif model_index == 493:
        return se_densenet_full_in_loop.se_densenet201()
    elif model_index == 494:
        return se_densenet_full_in_loop.se_densenet161()
    elif model_index == 495:
        return se_densenet_full_in_loop.se_densenet121(pretrained=True)
    elif model_index == 496:
        return se_densenet_full_in_loop.se_densenet169(pretrained=True)
    elif model_index == 497:
        return se_densenet_full_in_loop.se_densenet201(pretrained=True)
    elif model_index == 498:
        return se_densenet_full_in_loop.se_densenet161(pretrained=True)

    # se_densenet_w_block
    elif model_index == 410:
        return se_densenet_w_block.SEDenseNet()
    elif model_index == 411:
        return se_densenet_w_block.se_densenet121()
    elif model_index == 412:
        return se_densenet_w_block.se_densenet169()
    elif model_index == 413:
        return se_densenet_w_block.se_densenet201()
    elif model_index == 414:
        return se_densenet_w_block.se_densenet161()
    elif model_index == 415:
        return se_densenet_w_block.se_densenet121(pretrained=True)
    elif model_index == 416:
        return se_densenet_w_block.se_densenet169(pretrained=True)
    elif model_index == 417:
        return se_densenet_w_block.se_densenet201(pretrained=True)
    elif model_index == 418:
        return se_densenet_w_block.se_densenet161(pretrained=True)

    # se_densenet_w_block_a
    elif model_index == 4000:
        return se_densenet_w_block_a.se_densenet121()
    # se_densenet_w_block_a
    elif model_index == 4001:
        return se_densenet_w_block_a_n_1__1_nconv.se_densenet121()
    # se_densenet_w_block_b_Inception
    elif model_index == 4002:
        return se_densenet_w_block_b_Inception.se_densenet121()
    # se_densenet_w_block_c_Inception_YXY
    elif model_index == 4003:
        return se_densenet_w_block_c_Inception_YXY.se_densenet121()
    # se_densenet_w_block_ab
    elif model_index == 4004:
        return se_densenet_w_block_ab.se_densenet121()
    # se_densenet_w_block_ac
    elif model_index == 4005:
        return se_densenet_w_block_ac.se_densenet121()

    # se_densenet_w_block_d_residual
    elif model_index == 4006:
        return se_densenet_w_block_d_residual.se_densenet121()
    # se_densenet_w_block_e_residual_YXY
    elif model_index == 4007:
        return se_densenet_w_block_e_residual_YXY.se_densenet121()
    # se_densenet_w_block_f_LeakyReLU
    elif model_index == 4008:
        return se_densenet_w_block_f_LeakyReLU.se_densenet121()
    # se_densenet_w_block_g_dynamicReLU
    elif model_index == 4009:
        return se_densenet_w_block_g_dynamicReLU_YXY.se_densenet121()
    # se_densenet_w_block_h_SN_Switchable_N
    elif model_index == 4010:
        return se_densenet_w_block_h_SN_Switchable_N.se_densenet121()

    # se_densenet_w_block_d_residual_YXY
    elif model_index == 4011:
        return se_densenet_w_block_acegh.se_densenet121()
    # se_densenet_w_block_d_residual_YXY
    elif model_index == 4012:         #这个的bn_size为1，和SE的一样
        return se_densenet_w_block_acegh_a.se_densenet121()


    elif model_index == 4013:         #这个的bn_size为4，和SE的一样
        return se_densenet_w_block_ce.se_densenet121()
    elif model_index == 4014:         #这个的bn_size为4，和SE的一样
        return se_densenet_w_block_c56_Inception_YXY.se_densenet121()
    elif model_index == 4015:         #这个的bn_size为1
        return se_densenet_w_block_ce56_Inception_res_YXY.se_densenet121()
    elif model_index == 4016:         #这个的bn_size为4，和SE的一样
        return se_densenet_w_block_ce56_Inception_3_3_res_YXY.se_densenet121()

    elif model_index == 4510:
        return models_32.vision.densenet121_dropout(pretrained=False, drop_rate=0.2)
    elif model_index == 4017:         #这个的bn_size为4，和SE的一样
        return densenet_ce56_Inception_3_3_res_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4018:         #这个的bn_size为1
        return se_densenet_w_block_c56_Inception_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4019:         #这个的bn_size为4，和SE的一样
        return se_densenet_w_block_ce56_Inception_3_3_res_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4020:
        return models_32.vision.resnet101()
    elif model_index == 320:         #不能使用
        return models_32.vision.googlenet()

    # elif model_index == 331:       # 'googlenet'    可以使用    这个代码是100类别的
    #     from model_DualT.model_YXY_google2_11.googlenet import googlenet
    #     return googlenet(num_class=2)              #这样不使用预训练是可以进行训练的

    elif model_index == 2310:
        return models_32.Resnet18()

    elif model_index == 4110:
        return se_densenet_w_block.se_densenet121(drop_rate=0.2)

    elif model_index == 4021:         #这个的bn_size为4，和SE的一样
        return densenet_ce56_Inception_3_3_res_onlyconv_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4022:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_3_3_res.se_densenet121(drop_rate=0.2)
    elif model_index == 4023:         #这个的bn_size为4，和SE的一样
        return densenet_w_block.se_densenet121(num_classes=num_classes, drop_rate=0.2)
    elif model_index == 402311:         #这个的bn_size为4，和SE的一样
        return densenet_w_block.se_densenet121(pretrained=True, drop_rate=0.2)
    elif model_index == 402399:         #这个的bn_size为4，和SE的一样
        return densenet_w_block.se_densenet121(num_classes=1000, drop_rate=0.2)
    elif model_index == 4024:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_3_3_res_InceA1_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4025:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res.se_densenet121(drop_rate=0.2)
    elif model_index == 4026:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA1_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4027:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA1_n1_1n_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4028:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA2_a_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4029:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA1_trans_Ince_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4030:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_Crop_trans_Ince_YXY.se_densenet121(drop_rate=0.2)      #   TransitionLayer里面的firstbatchsize=16
    elif model_index == 4031:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_Crop_Pool_trans_Ince_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4032:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA2_a_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4033:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA2_b_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4034:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA1_trans_Ince_a_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4035:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA2_c_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4036:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA2_stride2_3113_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4037:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA1_trans_Ince_b_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4038:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA1a_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4039:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA1b_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4040:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA2_d_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4041:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA1_trans_Ince_c_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4042:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA2_e_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4043:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA1c_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4044:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA1_trans_Ince_d_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4045:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_Ince_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4046:         #这个的bn_size为4，和SE的一样
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4047:         # 全部都加
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_Crop_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4048:         #     这里是在过渡层上不添加Inception
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_Crop_bujia_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4049:         #    在4048基础上， 这里是前2个Inception不加残差
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_Crop_bujia_cancha_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4050:         #     这里是DenseNet块里面也不加残差
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_Crop_bujia_cancha_denseblock_also_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4051:         # 这里发现残差有问题，选择不加残差
        return densenet_w_block_e_residual_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4052:         # 这里发现Densenet第一个模块有问题，是不需要预激活的
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_Crop_yuReLU_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4053:         #     这里是只使用残差连接
        return densenet_w_block_e_new_residual_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4054:         #    添加最大池化操作在Inception
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Crop_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4055:         #     把密集块中的残差连接删除掉
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4056:         #     把密集块中的残差连接删除掉,然后还删除Inception模块中的残差连接
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_Ince_pool_Nres_Crop_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4057:         #    10_4057_在4055基础上给Inception的残差连接加最大池化
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nrespool_Crop_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4058:         #    10_4058_在4055基础上将DenseNet中过渡层的Inception替换为inceptionV3C
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInceV3_pool_Nres_Crop_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4059:         #    基于最好的效果4055      进行消融实验，第一个就是把过渡层Inception模块去掉，只保留前面2层过渡层
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_A.se_densenet121(drop_rate=0.2)
    elif model_index == 4060:         #    基于最好的效果4055      进行消融实验，第一个就是把前面2层过渡层去掉，只保留中心环切的代码，缩小七分之六尺寸
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInceno_pool_Nres_Crop_YXY_A.se_densenet121(drop_rate=0.2)
    elif model_index == 40551:         #     过渡层使用2*2的平均池化      原本使用的3*3最大池化        那么后面需要测试使用2*2的最大池化
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool2_2_Nres_Crop_YXY.se_densenet121(drop_rate=0.2)

    #  这个看错了，残差连接没有使用池化操作，使用的是步长为2的卷积进行的处理
    # elif model_index == 40552:         #     过渡层使用2*2的最大池化     测试使用2*2的最大池化     这个测试下残差连接使用最大池化，原本的40551使用的是平均池化的残差连接
    #     return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool2_2Mres_Nres_Crop_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 40553:         #     过渡层使用2*2的最大池化     测试使用2*2的最大池化
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool2_2M_Nres_Crop_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 40554:         #     过渡层使用2*2的最大池化     测试使用2*3的最大池化
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool2_2M_Nres_Crop_YXY_A.se_densenet121(drop_rate=0.2)
    elif model_index == 40555:         #     过渡层使用2*2的最大池化     测试使用3*2的最大池化
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool2_2M_Nres_Crop_YXY_B.se_densenet121(drop_rate=0.2)
    elif model_index == 40591:         #    基于4059,测试前面2层使用什么结构最合适，这里发现使用残差链接并不是很有效。因此去掉残差连接，直接堆叠2个模块        ，后续再看看是否需要使用2*2的池化核去替代3*3的池化核，因为在40553的实验中，发现2*2的池化核效果高于3*3的池化核，一个点，但不是很稳定，因此需要测试下3*2或者2*3的池化核
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_B.se_densenet121(drop_rate=0.2)
    elif model_index == 40592:         #    基于4059,测试前面2层使用什么结构最合适，这里发现使用残差链接并不是很有效。因此去掉残差连接，直接堆叠2个模块        ，使用2*3的池化核去替代3*3的池化核，
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_C.se_densenet121(drop_rate=0.2)
    elif model_index == 40593:         #    基于4059,测试前面2层使用什么结构最合适，这里发现使用残差链接并不是很有效。            在40591的结果后发现前面2层使用池化效果不好，因此采用步长为2的卷积试试，暂时原始结构不变化
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_D.se_densenet121(drop_rate=0.2)
    elif model_index == 40594:         #    基于4059,测试前面2层使用什么结构最合适，这里发现使用残差链接并不是很有效。            现在把前面2层改为一层结构，并且使用inception步长2卷积加最大池化，全部加上最大池化，这里使用3*3的最大池化，和原始文章的初始卷积层后池化一样
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_E.se_densenet121(drop_rate=0.2)
    elif model_index == 40595:         #    基于4059,测试前面2层使用什么结构最合适，这里发现使用残差链接并不是很有效。            现在把前面2层改为一层结构，并且使用inception步长2卷积加最大池化，全部加上最大池化，最后再添加一个残差连接
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_F.se_densenet121(drop_rate=0.2)
    elif model_index == 40596:         #    基于40593,测试使用残差链接            测试结果显示添加残差连接后，训练得到的结果更加稳定，效果也更好哦
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_DA.se_densenet121(drop_rate=0.2)

    #           现在看来最好效果极可能是40598，      40596效果也很不错
    elif model_index == 40597:         #    基于4059,现在把前面2层改为一层结构，并且使用inception步长2卷积加最大池化，全部加上2*2最大池化，最后再添加一个残差连接
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_G.se_densenet121(drop_rate=0.2)
    elif model_index == 40598:         #    基于4059,现在把前面2层改为一层结构，并且使用inception步长2卷积加最大池化，全部加上2*2最大池化，不添加一个残差连接
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_H.se_densenet121(drop_rate=0.2)
    elif model_index == 40599:         #    基于40593,测试使用单结构添加残差的inception，后面第二层还是和原始网络的3*3最大池化一样结构
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_I.se_densenet121(drop_rate=0.2)
    elif model_index == 40560:         #    基于40593,测试使用单结构不添加残差的inception，后面第二层还是和原始网络的3*3最大池化一样结构
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_J.se_densenet121(drop_rate=0.2)
    elif model_index == 4061:         #    基于最好的效果4055      进行消融实验，把中心环切的代码去掉           #这个也是全部模块都去掉了
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInceno_pool_Nres_Crop_YXY_B.se_densenet121(drop_rate=0.2)
    elif model_index == 40561:         #    基于40560,测试使用单结构添加残差的inception，后面第二层还是和原始网络的3*3最大池化一样结构,这里2个将最后池化操作前面的BN+reLu删除掉，顺便检测下残差连接的有效性。     实验证明删除之后效果变差了
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_K.se_densenet121(drop_rate=0.2)
    elif model_index == 40562:         #    基于40560,测试使用单结构不添加残差的inception，后面第二层还是和原始网络的3*3最大池化一样结构
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_L.se_densenet121(drop_rate=0.2)
    elif model_index == 40563:         #    基于40598     使用池化和步长为2的卷积哪个好，因为我已经是2步长加池化层了，按理说是没必要给2个池化层，但是也得尝试下，那么搞个40563试试
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_M.se_densenet121(drop_rate=0.2)
    elif model_index == 40564:         #    基于40598,现在把前面2层改为一层结构，并且使用inception步长2卷积加最大池化，全部加上2*2最大池化，不添加一个残差连接         最后将2*2池化前面使用BN+ReLU，上面40561和40562测试的BN+ReLU使用的3*3的池化核，所以没法进行比较
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool_Nres_Crop_YXY_N.se_densenet121(drop_rate=0.2)
    elif model_index == 4070:         #    基于4055和40596     4055是全部结构，  40596是删除残差连接的2个InceptionA,步长为2的卷积
        return densenet_w_block_ce_1_1_InceA2_e_trans_resInce_Nres_Crop_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4071:         #    基于4055和40598     4055是全部结构，  40598是删除残差连接的1个InceptionA,而且使用2*2最大池化
        return densenet_w_block_ce_1_1_InceA1_e_trans_resInce_2_2pool_Nres_Crop_YXY.se_densenet121(drop_rate=0.2)

    # 这里发现过渡层使用的都是3*3的最大池化，因此使用2*2池化，基于40553的2*2池化 但是不稳定，再次设计4072和4073,测试下结果如何
    elif model_index == 4072:         #    基于4070
        return densenet_w_block_ce_1_1_InceA2_e_trans_resInce_Nres_Crop_YXYA.se_densenet121(drop_rate=0.2)
    elif model_index == 4073:         #    基于4073
        return densenet_w_block_ce_1_1_InceA1_e_trans_resInce_2_2pool_Nres_Crop_YXYA.se_densenet121(drop_rate=0.2)
    elif model_index == 4074:         #     基于40553         把前面2层的池化也改为2*2最大池化
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool2_2M_Nres_Crop_YXYC.se_densenet121(drop_rate=0.2)

#     基于40553作消融实验，
    elif model_index == 4075:         #    只保留网络初始两个残差多通路模块
        return densenet_w_block_ce_1_1_resInce_pool2_2M_Nres_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4076:         #    将40553只保留三个替代过渡块的残差多通路模块
        return densenet_w_block_ce_pool2_2M_Nres_YXY.se_densenet121(drop_rate=0.2)
    elif model_index == 4077:         #    将40553中全部的Inception去掉,   也就是只保留部分裁切和邻近插值      #这个和4060代码一样
        return densenet_w_block_ce_1_1_Crop_YXY.se_densenet121(drop_rate=0.2)
    # elif model_index == 4060:         #    将40553中全部的Inception去掉,   也就是只保留部分插值
    #     return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInceno_pool_Nres_Crop_YXY_A.se_densenet121(drop_rate=0.2)
    elif model_index == 4078:         #    将40553中前面2个过渡层去掉,移除网络初始2个残差多通路模块来证明中心裁切残差多通路结构的有效性
        return densenet_w_block_ce_1_1_res_e_trans_resInce_pool2_2M_Nres_Crop_YXY.se_densenet121(drop_rate=0.2)


    # 后面开始全部是56*56的尺寸
    elif model_index == 4080:         #     基于40553，修改输入尺寸为56.
        return densenet_w_block_ce_1_1_res_InceA2_e_trans_resInce_pool2_2M_Nres_Crop_56_56_YXY.se_densenet121(drop_rate=0.2)
    # 后面开始全部是56*56的尺寸
    elif model_index == 4081:         #     基于4023，修改输入尺寸为56.
        return densenet_w_block56.se_densenet121(drop_rate=0.2)
    elif model_index == 4082:         #     基于4023，修改输入尺寸为56.
        return se_densenet_w_block56.se_densenet121(drop_rate=0.2)

    # 以DenseNet为基础，开发了一个低内存数据流（Low Memory Traffic）的CNN架构，称为HarDNet
    # if model_index == 4010:
    #     return


    elif model_index == 4100:
        from model_YXY_densenet.Pytorch_HarDNet.hubconf import hardnet68
        return hardnet68()
    elif model_index == 4101:
        from model_YXY_densenet.Pytorch_HarDNet.hubconf import hardnet68
        return hardnet68(pretrained=True)
    elif model_index == 4102:
        from model_YXY_densenet.Pytorch_HarDNet.hubconf import hardnet85
        return hardnet85()
    elif model_index == 4103:
        from model_YXY_densenet.Pytorch_HarDNet.hubconf import hardnet85
        return hardnet85(pretrained=True)
    elif model_index == 4104:
        from model_YXY_densenet.Pytorch_HarDNet.hubconf import hardnet68ds
        return hardnet68ds()
    elif model_index == 4105:
        from model_YXY_densenet.Pytorch_HarDNet.hubconf import hardnet68ds
        return hardnet68ds(pretrained=True)
    elif model_index == 4106:
        from model_YXY_densenet.Pytorch_HarDNet.hubconf import hardnet39ds
        return hardnet39ds()
    elif model_index == 4107:
        from model_YXY_densenet.Pytorch_HarDNet.hubconf import hardnet39ds
        return hardnet39ds(pretrained=True)


    # pretrained=False  不能使用，因为1000类的预训练模型，我们的数据集是2分类
    # num_classes=1000和num_classes=2区别不大，都是训练效果不好，关键是损失函数一点都不变化，网络暂时先放着
    elif model_index == 51:
        return models_32.vision.squeezenet1_0()
    elif model_index == 52:
        return models_32.vision.squeezenet1_0(num_classes=2)
    elif model_index == 53:
        return models_32.vision.squeezenet1_0(pretrained=True)
    # 54这个代码不能使用，因为预训练模型的类别不是2，而是1000
    elif model_index == 54:
        return models_32.vision.squeezenet1_0(num_classes=2, pretrained=True)
    elif model_index == 55:
        return models_32.vision.squeezenet1_1()
    elif model_index == 56:
        return models_32.vision.squeezenet1_1(num_classes=2)
    elif model_index == 57:
        return models_32.vision.squeezenet1_1(pretrained=True)


    # 可以使用
    elif model_index == 6:
        return models_32.vision.mobilenet_v2()
    elif model_index == 61:
        return models_32.vision.mobilenet_v2(pretrained=True)
    elif model_index == 62:
        return models_32.vision.mobilenet_v2(num_classes=2)
    elif model_index == 63:
        return models_32.Mobilenetv2()
    elif model_index == 64:
        return models_32.Mobilenetv2(pretrained=True)
    elif model_index == 65:
        from model_DualT.model_YXY_google2_11.mobilenet import mobilenet
        return mobilenet(alpha=1, class_num=2)
    elif model_index == 66:            # 没有找到预训练模型，也就不写预训练的了，而且也没有fc层，不好进行更改
        from model_DualT.model_YXY_google2_11.mobilenet import mobilenet
        return mobilenet(alpha=1, class_num=2)
    elif model_index == 661:
        from model_DualT.model_YXY_google2_11.mobilenetv3 import mobilenetv3
        return mobilenetv3(n_class=2)
    elif model_index == 662:                #没有找到预训练模型，FileNotFoundError: [Errno 2] No such file or directory: 'mobilenetv3_small_67.4.pth.tar'
        #  装载模型进去也还是不能预训练   Unexpected key(s) in state_dict: "epoch", "state_dict", "best_prec1", "best_prec5", "optimizer".
        from model_DualT.model_YXY_google2_11.mobilenetv3 import mobilenetv3
        return mobilenetv3(pretrained=True, n_class=2)
    elif model_index == 663:                #没有找到预训练模型，也就不写预训练的了
        from model_DualT.model_YXY_google2_11.mobilenetv3 import mobilenetv3
        return mobilenetv3(pretrained=True, n_class=1000)
    elif model_index == 664:        # GoogLeNet
        from model_DualT.model_YXY_google2_11.mobilenetv3_2 import mobilenetv3_2
        return mobilenetv3_2(num_classes=2)
    elif model_index == 665:                #没有找到预训练模型，FileNotFoundError: [Errno 2] No such file or directory: 'mobilenetv3_small_67.4.pth.tar'
        from model_DualT.model_YXY_google2_11.mobilenetv3_2 import mobilenetv3_2
        return mobilenetv3_2(pretrained=True, num_classes=2)
    elif model_index == 666:                #没有找到预训练模型，也就不写预训练的了
        from model_DualT.model_YXY_google2_11.mobilenetv3_2 import mobilenetv3_2
        return mobilenetv3_2(pretrained=True, num_classes=1000)


    # 可以使用
    elif model_index == 71:
        return models_32.vision.shufflenet_v2_x0_5()
    elif model_index == 72:
        return models_32.vision.shufflenet_v2_x1_0()
    elif model_index == 73:
        return models_32.vision.shufflenet_v2_x1_5()
    elif model_index == 74:
        return models_32.vision.shufflenet_v2_x2_0()
    elif model_index == 75:
        return models_32.vision.shufflenet_v2_x0_5(pretrained=True)
    elif model_index == 76:
        return models_32.vision.shufflenet_v2_x1_0(pretrained=True)
    elif model_index == 77:
        return models_32.vision.shufflenet_v2_x1_5(pretrained=True)
    elif model_index == 78:
        return models_32.vision.shufflenet_v2_x2_0(pretrained=True)


    # 不知道可不可以使用，因为占用很大的GPU空间
    elif model_index == 80:
        return models_32.Efficientnet(model_name='efficientnet-b0')
    elif model_index == 81:
        return models_32.Efficientnet(model_name='efficientnet-b1')
    elif model_index == 82:
        return models_32.Efficientnet(model_name='efficientnet-b2')
    elif model_index == 83:
        return models_32.Efficientnet(model_name='efficientnet-b3')
    elif model_index == 84:
        return models_32.Efficientnet(model_name='efficientnet-b4')
    elif model_index == 85:
        return models_32.Efficientnet(model_name='efficientnet-b5')
    elif model_index == 86:
        return models_32.Efficientnet(model_name='efficientnet-b6')
    elif model_index == 87:
        return models_32.Efficientnet(model_name='efficientnet-b7')
    elif model_index == 88:
        return models_32.Efficientnet(model_name='efficientnet-b8')
    elif model_index == 810:
        return models_32.Efficientnet(pretrained=True, model_name='efficientnet-b0')
    elif model_index == 811:
        return models_32.Efficientnet(pretrained=True, model_name='efficientnet-b1')
    elif model_index == 812:
        return models_32.Efficientnet(pretrained=True, model_name='efficientnet-b2')
    elif model_index == 813:
        return models_32.Efficientnet(pretrained=True, model_name='efficientnet-b3')
    elif model_index == 814:
        return models_32.Efficientnet(pretrained=True, model_name='efficientnet-b4')
    elif model_index == 815:
        return models_32.Efficientnet(pretrained=True, model_name='efficientnet-b5')
    elif model_index == 816:
        return models_32.Efficientnet(pretrained=True, model_name='efficientnet-b6')
    elif model_index == 817:
        return models_32.Efficientnet(pretrained=True, model_name='efficientnet-b7')
    elif model_index == 818:
        return models_32.Efficientnet(pretrained=True, model_name='efficientnet-b8')


    # SEnet
    elif model_index == 91:
        from model_DualT.model_YXY_google2_11.senet import seresnet18
        return seresnet18(class_num=2)
    elif model_index == 9101:
        from model_DualT.model_YXY_google2_11.senet_T import seresnet18
        return seresnet18(class_num=2)
    elif model_index == 92:                #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
        from model_DualT.model_YXY_google2_11.senet import seresnet18
        return seresnet18(pretrained=True, class_num=2)
    elif model_index == 93:
        from model_DualT.model_YXY_google2_11.senet import seresnet34
        return seresnet34(class_num=2)
    elif model_index == 94:                #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
        from model_DualT.model_YXY_google2_11.senet import seresnet34
        return seresnet34(pretrained=True, class_num=2)
    elif model_index == 95:
        from model_DualT.model_YXY_google2_11.senet import seresnet50
        return seresnet50(class_num=2)
    elif model_index == 96:                #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
        from model_DualT.model_YXY_google2_11.senet import seresnet50
        return seresnet50(pretrained=True, class_num=2)
    elif model_index == 97:
        from model_DualT.model_YXY_google2_11.senet import seresnet101
        return seresnet101(class_num=2)
    elif model_index == 98:                #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
        from model_DualT.model_YXY_google2_11.senet import seresnet101
        return seresnet101(pretrained=True, class_num=2)
    elif model_index == 99:
        from model_DualT.model_YXY_google2_11.senet import seresnet152
        return seresnet152(class_num=2)
    elif model_index == 90:                #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
        from model_DualT.model_YXY_google2_11.senet import seresnet152
        return seresnet152(pretrained=True, class_num=2)


    # 两种深层聚合(DLA)的结构:迭代深层聚合(IDA)和分层深层聚合(HDA)
    elif model_index == 911:
        from models_32.model_YXY_fullgood_13.models.dla import dla60_res2net
        return dla60_res2net()
    elif model_index == 912:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dla import dla60_res2net
        return dla60_res2net(pretrained=True)
    elif model_index == 913:
        from models_32.model_YXY_fullgood_13.models.dla import dla60_res2next
        return dla60_res2next()
    elif model_index == 914:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dla import dla60_res2next
        return dla60_res2next(pretrained=True)
    elif model_index == 915:
        from models_32.model_YXY_fullgood_13.models.dla import dla34
        return dla34()
    elif model_index == 916:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dla import dla34
        return dla34(pretrained=True)
    elif model_index == 917:
        from models_32.model_YXY_fullgood_13.models.dla import dla46_c
        return dla46_c()
    elif model_index == 918:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dla import dla46_c
        return dla46_c(pretrained=True)
    elif model_index == 919:
        from models_32.model_YXY_fullgood_13.models.dla import dla46x_c
        return dla46x_c()
    elif model_index == 920:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dla import dla46x_c
        return dla46x_c(pretrained=True)
    elif model_index == 921:
        from models_32.model_YXY_fullgood_13.models.dla import dla60x_c
        return dla60x_c()
    elif model_index == 922:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dla import dla60x_c
        return dla60x_c(pretrained=True)
    elif model_index == 923:
        from models_32.model_YXY_fullgood_13.models.dla import dla60
        return dla60()
    elif model_index == 924:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dla import dla60
        return dla60(pretrained=True)
    elif model_index == 925:
        from models_32.model_YXY_fullgood_13.models.dla import dla60x
        return dla60x()
    elif model_index == 926:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dla import dla60x
        return dla60x(pretrained=True)
    elif model_index == 927:
        from models_32.model_YXY_fullgood_13.models.dla import dla102
        return dla102()
    elif model_index == 928:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dla import dla102
        return dla102(pretrained=True)
    elif model_index == 929:
        from models_32.model_YXY_fullgood_13.models.dla import dla102x
        return dla102x()
    elif model_index == 930:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dla import dla102x
        return dla102x(pretrained=True)
    elif model_index == 931:
        from models_32.model_YXY_fullgood_13.models.dla import dla102x2
        return dla102x2()
    elif model_index == 932:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dla import dla102x2
        return dla102x2(pretrained=True)
    elif model_index == 933:
        from models_32.model_YXY_fullgood_13.models.dla import dla169
        return dla169()
    elif model_index == 934:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.dla import dla169
        return dla169(pretrained=True)


    # SEResNext
    elif model_index == 941:
        from models_32.model_YXY_se_resnet.PyTorch_SE_ResNext_master.model.model import se_resnet50
        return se_resnet50()
    elif model_index == 942:                #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
        from models_32.model_YXY_se_resnet.PyTorch_SE_ResNext_master.model.model import se_resnet50
        return se_resnet50(pretrained=True)
    elif model_index == 943:
        from models_32.model_YXY_se_resnet.PyTorch_SE_ResNext_master.model.model import se_resnet101
        return se_resnet101(num_classes=num_classes)
    elif model_index == 944:                #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
        from models_32.model_YXY_se_resnet.PyTorch_SE_ResNext_master.model.model import se_resnet101
        return se_resnet101(pretrained=True)
    # resnet 152略
    elif model_index == 945:
        from models_32.model_YXY_se_resnet.PyTorch_SE_ResNext_master.model.model import se_resnext50
        return se_resnext50()
    elif model_index == 946:                #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
        from models_32.model_YXY_se_resnet.PyTorch_SE_ResNext_master.model.model import se_resnext50
        return se_resnext50(pretrained=True)
    elif model_index == 947:
        from models_32.model_YXY_se_resnet.PyTorch_SE_ResNext_master.model.model import se_resnext101
        return se_resnext101(num_classes=num_classes)
    elif model_index == 948:                #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
        from models_32.model_YXY_se_resnet.PyTorch_SE_ResNext_master.model.model import se_resnext101
        return se_resnext101(pretrained=True)
    elif model_index == 949:
        from models_32.model_YXY_se_resnet.PyTorch_SE_ResNext_master.model.model import se_resnext152
        return se_resnext152()
    elif model_index == 940:                #没有找到预训练模型，因此不能使用True，也就是不能运行，也就不写预训练的了，但是有fc层可以进行修改
        from models_32.model_YXY_se_resnet.PyTorch_SE_ResNext_master.model.model import se_resnext152
        return se_resnext152(pretrained=True)


    # CondenseNet
    elif model_index == 951:
        from model_YXY_densenet.condense_net2.models.condensenet import CondenseNet
        return CondenseNet()
    elif model_index == 952:
        from model_YXY_densenet.condense_net2.models.condensenet_converted import CondenseNet
        return CondenseNet()
    elif model_index == 953:
        from model_YXY_densenet.condense_net2.models.densenet import DenseNet
        return DenseNet()
    elif model_index == 954:
        from model_YXY_densenet.condense_net2.models.densenet_LGC import DenseNet_LGC
        return DenseNet_LGC()

    # # 3D Densenet in 4-way Classification of Alzheimer's Disease
    elif model_index == 955:
        from model_YXY_densenet.Densenet_3D.model1 import generate_model
        return generate_model(121, num_classes=4, drop_rate=0.5, growth_rate=32)
    elif model_index == 956:
        from model_YXY_densenet.Densenet_3D.model2 import generate_model
        return generate_model(121, num_classes=4, drop_rate=0.5, growth_rate=22)
    elif model_index == 957:
        from model_YXY_densenet.Densenet_3D.model3 import generate_model
        return generate_model(121, num_classes=4, drop_rate=0.5, growth_rate=28)

    # HCGNets: Gated Convolutional Networks with Hybrid Connectivity for Image Classification
    elif model_index == 958:
        from model_YXY_densenet.HCGNet.models.HCGNet_CIFAR import HCGNet_A1
        return HCGNet_A1()
    elif model_index == 959:
        from model_YXY_densenet.HCGNet.models.HCGNet_CIFAR import HCGNet_A2
        return HCGNet_A2()
    elif model_index == 960:
        from model_YXY_densenet.HCGNet.models.HCGNet_CIFAR import HCGNet_A3
        return HCGNet_A3()
    elif model_index == 961:
        from model_YXY_densenet.HCGNet.models.HCGNet_ImageNet import HCGNet_B
        return HCGNet_B()
    elif model_index == 962:
        from model_YXY_densenet.HCGNet.models.HCGNet_ImageNet import HCGNet_C
        return HCGNet_C()

    # Attention is all you need: A Pytorch Implementation
    # elif model_index == 963:
        # from model_YXY_densenet.pytorch_implementation_of_dense_net_attention_is_all_you_need import
        # return
    # 由于这个位置不是DenseNet，暂时不作处理

    elif model_index == 964:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.regnet import regnetx_002
        return regnetx_002(pretrained=True)
    elif model_index == 965:
        from models_32.model_YXY_fullgood_13.models.regnet import regnetx_002
        return regnetx_002()
    elif model_index == 966:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.regnet import regnetx_320
        return regnetx_320(pretrained=True)
    elif model_index == 967:
        from models_32.model_YXY_fullgood_13.models.regnet import regnetx_320
        return regnetx_320()
    elif model_index == 968:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.regnet import regnety_002
        return regnety_002(pretrained=True)
    elif model_index == 969:
        from models_32.model_YXY_fullgood_13.models.regnet import regnety_002
        return regnety_002()
    elif model_index == 970:
        from models_32.model_YXY_fullgood_13.models.regnet import regnety_320
        return regnety_320()
    elif model_index == 971:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.regnet import regnety_320
        return regnety_320(pretrained=True)

    elif model_index == 9610:
        from models_32.model_YXY_fullgood_13.models.regnet import regnetx_008
        return regnetx_008()
    elif model_index == 9611:           # ([16, 896, 14, 14])
        from models_32.model_YXY_fullgood_13.models.regnet import regnetx_120
        return regnetx_120()
    elif model_index == 9612:           # [16, 896, 14, 14])
        from models_32.model_YXY_fullgood_13.models.regnet import regnetx_160
        return regnetx_160()
    elif model_index == 9613:           # ([16, 720, 14, 14])
        from models_32.model_YXY_fullgood_13.models.regnet import regnetx_080
        return regnetx_080()
    elif model_index == 9614:           # ([16, 1008, 7, 7])
        from models_32.model_YXY_fullgood_13.models.regnet import regnetx_032
        return regnetx_032()
    elif model_index == 9615:           # ([16, 1360, 7, 7])
        from models_32.model_YXY_fullgood_13.models.regnet import regnetx_040
        return regnetx_040()
    elif model_index == 9616:           # ([16, 912, 7, 7])
        from models_32.model_YXY_fullgood_13.models.regnet import regnetx_016
        return regnetx_016()


    elif model_index == 988:           # ([16, 1008, 7, 7])
        from models_32.model_YXY_fullgood_13.models.regnet import regnetx_032
        return regnetx_032()
    elif model_index == 9801:           # ([16, 1008, 7, 7])
        from models_32.model_YXY_fullgood_13.models.regnetLFZ import regnetx_032
        return regnetx_032()
    elif model_index == 980199:           # ([16, 1008, 7, 7])
        from models_32.model_YXY_fullgood_13.models.regnetLFZ import regnetx_032
        return regnetx_032(pretrained=True)






    elif model_index == 972:
        from models_32.nfnets.nfnets_pytorch.nfnets import NFNet
        return NFNet(num_classes=1000, variant='F0', stochdepth_rate=0.25, alpha=0.2, se_ratio=0.5, activation='gelu')
            # num_classes=config['num_classes'],    # variant=config['variant'],# F0 - F7      # stochdepth_rate=config['stochdepth_rate'],# 0-1, the probability that a layer is dropped during one step
            # alpha=config['alpha'],# Scaling factor at the end of each block            # se_ratio=config['se_ratio'],# Squeeze-Excite expansion ratio            # activation=config['activation']# or 'relu'


    #  这两个不同位置下载的，都运行的结果为固定0.5不动
    elif model_index == 973:
        from models_32.nfnets.deepmind_research.nfnets.nfnet import NFNet
        return NFNet(2)
    elif model_index == 974:              #   default='F0', type=str, choices=['F0', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7'], help='NFNet variants')
        from models_32.nfnets.simple_nfnet.model import NFNet
        return NFNet(num_classes=10, variant='F0', stochdepth_rate=0.25, alpha=0.2, se_ratio=0.5, activation='gelu')



    elif model_index == 975:               # 这个还是0.5
        from models_32.model_YXY_fullgood_13.models.nfnet import nfnet_f0
        return nfnet_f0()
    elif model_index == 976:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.nfnet import nfnet_f0
        return nfnet_f0(pretrained=True)
    elif model_index == 977:               # 这个还是0.5
        from models_32.model_YXY_fullgood_13.models.nfnet import nfnet_f0s
        return nfnet_f0s()
    elif model_index == 978:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.nfnet import nfnet_f0s
        return nfnet_f0s(pretrained=True)
    elif model_index == 979:               # 这个还是0.5
        from models_32.model_YXY_fullgood_13.models.nfnet import dm_nfnet_f0
        return dm_nfnet_f0()
    elif model_index == 980:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.nfnet import dm_nfnet_f0
        return dm_nfnet_f0(pretrained=True)
    elif model_index == 981:               # 这个还是0.5
        from models_32.model_YXY_fullgood_13.models.nfnet import nf_regnet_b0
        return nf_regnet_b0()
    elif model_index == 982:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.nfnet import nf_regnet_b0
        return nf_regnet_b0(pretrained=True)
    elif model_index == 983:            # 准确率可以提升
        from models_32.model_YXY_fullgood_13.models.nfnet import nf_resnet26
        return nf_resnet26()
    elif model_index == 984:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.nfnet import nf_resnet26
        return nf_resnet26(pretrained=True)
    elif model_index == 985:            # 准确率可以提升
        from models_32.model_YXY_fullgood_13.models.nfnet import nf_seresnet26
        return nf_seresnet26()
    elif model_index == 986:              #   预测模型是github上的，加载特别慢
        from models_32.model_YXY_fullgood_13.models.nfnet import nf_seresnet26
        return nf_seresnet26(pretrained=True)


    elif model_index == 987:
        from models_32.nfnets.CV_Backbones.tinynet_pytorch.tinynet import tinynet
        return tinynet()


    elif model_index == 101:
        from models_32.twotwo.EffNet.effnet import EffNet
        return EffNet(nb_classes=num_classes)

    elif model_index == 102:
        from models_32.twotwo.CV_Backbones_master.ghostnet_pytorch.ghostnet import ghostnet
        return ghostnet()

    elif model_index == 103:                # 无法计算计算量
        from models_32.twotwo.skipnet_master.imagenet.models import imagenet_rnn_gate_101
        return imagenet_rnn_gate_101()

    elif model_index == 104:
        from models_32.twotwo.Swin_Transformer_main.models.swin_transformer import SwinTransformer
        return SwinTransformer()

    elif model_index == 1040:
        from models_32.twotwo.Swin_Transformer_main.models.swin_transformer import SwinTransformer_b
        return SwinTransformer_b(num_classes=num_classes)

    elif model_index == 1041:
        from models_32.twotwo.Swin_Transformer_main.models.swin_transformer import SwinTransformer_b_pre
        return SwinTransformer_b_pre(pretrained=True, num_classes=num_classes)

    elif model_index == 105:
        model_type = "b"        # 超出8g显存
        from models_32.twotwo.Swin_Transformer_V2.swin_transformer_v2.model import swin_transformer_v2_t, swin_transformer_v2_s, \
            swin_transformer_v2_b,swin_transformer_v2_l,swin_transformer_v2_h,swin_transformer_v2_g, ClassificationModelWrapper
        # Init model
        if model_type == "t":
            model_function = swin_transformer_v2_t
            output_channels = 768
        elif model_type == "s":
            model_function = swin_transformer_v2_s
            output_channels = 768
        elif model_type == "b":
            model_function = swin_transformer_v2_b
            output_channels = 1024
        elif model_type == "l":
            model_function = swin_transformer_v2_l
            output_channels = 1536
        elif model_type == "h":
            model_function = swin_transformer_v2_h
            output_channels = 2816
        else:
            model_function = swin_transformer_v2_g
            output_channels = 4096
        model = ClassificationModelWrapper(model=model_function(input_resolution=(224, 224), window_size=7, dropout_path=0.1,
                        use_deformable_block=False), number_of_classes=num_classes, output_channels=output_channels)
        return model

    elif model_index == 1051:
        from models_32.twotwo.Swin_Transformer_V2.swin_transformer_v2.model import swin_transformer_v2_t, swin_transformer_v2_s, \
            swin_transformer_v2_b,swin_transformer_v2_l,swin_transformer_v2_h,swin_transformer_v2_g, ClassificationModelWrapper
        model_type = "s"        # 超出8g显存
        # Init model
        if model_type == "t":
            model_function = swin_transformer_v2_t
            output_channels = 768
        elif model_type == "s":
            model_function = swin_transformer_v2_s
            output_channels = 768
        elif model_type == "b":
            model_function = swin_transformer_v2_b
            output_channels = 1024
        elif model_type == "l":
            model_function = swin_transformer_v2_l
            output_channels = 1536
        elif model_type == "h":
            model_function = swin_transformer_v2_h
            output_channels = 2816
        else:
            model_function = swin_transformer_v2_g
            output_channels = 4096
        model = ClassificationModelWrapper(model=model_function(input_resolution=(224, 224), window_size=7, dropout_path=0.1,
                        use_deformable_block=False), number_of_classes=num_classes, output_channels=output_channels)
        return model


    elif model_index == 106:
        from models_32.twotwo.RepLKNet.replknet import create_RepLKNet31B
        # return create_RepLKNet31B(num_classes=num_classes, out_indices=(0, 1, 2, 3))
        return create_RepLKNet31B(num_classes=2, out_indices=None)

    elif model_index == 1070:
        from models_32.twotwo.ConvNeXt_main.models.convnext import convnext_tiny
        return convnext_tiny()
    elif model_index == 1071:
        from models_32.twotwo.ConvNeXt_main.models.convnext import convnext_small
        return convnext_small()
    elif model_index == 107:
        from models_32.twotwo.ConvNeXt_main.models.convnext import convnext_base
        return convnext_base()
    elif model_index == 1071:
        from models_32.twotwo.ConvNeXt_main.models.convnext import convnext_base_pre
        return convnext_base_pre(pretrained=True, num_classes=num_classes)


    elif model_index == 108:
        from models_32.twotwo.Neighborhood_Attention_Transformer.classification.nat import nat_small
        return nat_small()

    elif model_index == 1080:
        from models_32.twotwo.Neighborhood_Attention_Transformer.classification.nat import nat_mini
        return nat_mini()

    elif model_index == 1081:
        from models_32.twotwo.Neighborhood_Attention_Transformer.classification.nat import nat_tiny
        return nat_tiny()

    elif model_index == 1082:
        from models_32.twotwo.Neighborhood_Attention_Transformer.classification.nat import nat_small
        return nat_small()

    elif model_index == 1083:
        from models_32.twotwo.Neighborhood_Attention_Transformer.classification.nat import nat_base
        return nat_base()

    elif model_index == 1084:
        from models_32.twotwo.Neighborhood_Attention_Transformer.classification.nat import nat_small
        return nat_small(pretrained=True)

    elif model_index == 109:
        from models_32.model_YXY_se_resnet.res2net.res2net import res2net101
        return res2net101()

    elif model_index == 110:
        from models_32.twotwo.ELSA_Swin.elsa_swin import elsa_swin_tiny
        return elsa_swin_tiny()

    elif model_index == 1001:
        from models_32.twotwo.DAT.dat import DAT_tiny
        return DAT_tiny()

    elif model_index == 1002:
        from models_32.twothree.EdgeNeXt.models.model import edgenext_base
        return edgenext_base()
    elif model_index == 1003:
        from models_32.twothree.EdgeNeXt.models.model import edgenext_small
        return edgenext_small()
    elif model_index == 100399:
        from models_32.twothree.EdgeNeXt.models.model import edgenext_small
        return edgenext_small(pretrained=True)

    elif model_index == 1004:
        from models_32.twothree.Conformer.models import Conformer_small_patch16
        return Conformer_small_patch16()
    elif model_index == 1005:
        from models_32.twothree.Conformer.models import Conformer_base_patch16
        return Conformer_base_patch16()

    elif model_index == 1006:
        from models_32.twothree.Vit_Slim import deit_tiny_distilled_patch16_224
        return deit_tiny_distilled_patch16_224()
    elif model_index == 1007:       # 提高输出可读性Params(M)是 86.377M提高输出可读性MACs(G)是 16.849G
        from models_32.twothree.Vit_Slim import deit_base_patch16_224
        return deit_base_patch16_224()
    elif model_index == 1008:       # 提高输出可读性Params(M)是 86.377M提高输出可读性MACs(G)是 16.849G
        from models_32.twothree.Vit_Slim.vision_transformer import vit_base_patch16_224
        return vit_base_patch16_224()
    elif model_index == 1009:       #提高输出可读性Params(M)是 87.146M提高输出可读性MACs(G)是 16.934G
        from models_32.twothree.Vit_Slim import deit_base_distilled_patch16_224
        return deit_base_distilled_patch16_224()

    elif model_index == 1010:       #提高输出可读性Params(M)是 102.405M提高输出可读性MACs(G)是 16.865G
        from models_32.twothree.SSF.vision_transformer import vit_base_patch16_224_in21k
        return vit_base_patch16_224_in21k()

    # https://mp.weixin.qq.com/s/atmDSep4h2eC7vQlYILQtw
    # https://m.thepaper.cn/baijiahao_17927341
    # 这个代码是VPT，上面那个是SSF，这两个才是微调的代码，实现很复杂，且效果没看到在哪里
    elif model_index == 1011:       #提高输出可读性Params(M)是 85.762M提高输出可读性MACs(G)是 17.273G
        from models_32.twothree.vpt.vit_models import ViT
        return ViT()

    elif model_index == 1013:       # 提高输出可读性Params(M)是 13.992M提高输出可读性MACs(G)是 1.922G
        from model_DualT.two_d.metaformer import metaformer_pppa_s12_224
        return metaformer_pppa_s12_224()

    elif model_index == 1015:       # 提高输出可读性Params(M)是 11.894M提高输出可读性MACs(G)是 1.819G
        from model_DualT.two_d.poolformer import poolformer_s12
        return poolformer_s12()
    elif model_index == 1016:       # 提高输出可读性Params(M)是 21.348M提高输出可读性MACs(G)是 3.405G
        from model_DualT.two_d.poolformer import poolformer_s24
        return poolformer_s24()
    elif model_index == 1017:       # 提高输出可读性Params(M)是 13.992M提高输出可读性MACs(G)是 1.922G
        from model_DualT.two_d.poolformer import poolformer_s36
        return poolformer_s36()
    elif model_index == 1018:       # 提高输出可读性Params(M)是 13.992M提高输出可读性MACs(G)是 1.922G
        from model_DualT.two_d.poolformer import poolformer_m48
        return poolformer_m48()

    elif model_index == 1019:       # 提高输出可读性Params(M)是 21.926M提高输出可读性MACs(G)是 19.365G
        from model_DualT.two_d.coat import coat_small
        return coat_small()

    elif model_index == 1021:       # 提高输出可读性Params(M)是 19.594M提高输出可读性MACs(G)是 4.062G
        from model_DualT.two_d.cls_cvt import ConvolutionalVisionTransformer
        return ConvolutionalVisionTransformer(in_chans=3, num_classes=num_classes, choice='cvt13')
    elif model_index == 1022:       # 提高输出可读性Params(M)是 31.208M提高输出可读性MACs(G)是 6.512G
        from model_DualT.two_d.cls_cvt import ConvolutionalVisionTransformer
        return ConvolutionalVisionTransformer(in_chans=3, num_classes=num_classes, choice='cvt21')

    elif model_index == 1023:       # 提高输出可读性Params(M)是 9.405M提高输出可读性MACs(G)是 1.233G
        from model_DualT.two_d.cmt import cmt_ti
        return cmt_ti()
    elif model_index == 1024:       # 提高输出可读性Params(M)是 15.073M提高输出可读性MACs(G)是 2.050G
        from model_DualT.two_d.cmt import cmt_xs
        return cmt_xs()
    elif model_index == 1025:       # 提高输出可读性Params(M)是 25.941M提高输出可读性MACs(G)是 3.912G
        from model_DualT.two_d.cmt import cmt_s
        return cmt_s()
    elif model_index == 1026:       # 提高输出可读性Params(M)是 45.184M提高输出可读性MACs(G)是 6.866G
        from model_DualT.two_d.cmt import cmt_b
        return cmt_b()



    elif model_index == 1031:       # 提高输出可读性Params(M)是 45.184M提高输出可读性MACs(G)是 6.866G
        from models_32.oldtwo.VGNetG import VGNetG
        return VGNetG(num_classes=num_classes)
    elif model_index == 1033:       #
        from models_32.oldtwo.capsules import capsules          # A, B, C, D = 64, 8, 16, 16
        # return capsules(A=64, B=8, C=16, D=16, E=num_classes, iters_routings=[2, 2, 2])     # 32-》16-》8
        return capsules(A=56, B=7, C=14, D=14, E=num_classes, iters_routings=[2, 2, 2])     # 32-》14-》7


    elif model_index == 1035:       # 提高输出可读性Params(M)是 84.277M提高输出可读性MACs(G)是 15.890G
        from model_DualT.two_d.xcit import xcit_medium_24_p16
        return xcit_medium_24_p16()
    elif model_index == 1036:       #  47.582M 8.954G
        from model_DualT.two_d.xcit import xcit_small_24_p16
        return xcit_small_24_p16()
    elif model_index == 1037:       # 3.037M 539.988M
        from model_DualT.two_d.xcit import xcit_nano_12_p16
        return xcit_nano_12_p16()
    elif model_index == 1038:       # 26.166M MACs(G)是 18.521G
        from model_DualT.two_d.xcit import xcit_small_12_p8
        return xcit_small_12_p8()
    elif model_index == 1039:       #  12.063M 8.866G
        from model_DualT.two_d.xcit import xcit_tiny_24_p8
        return xcit_tiny_24_p8()
    elif model_index == 1043:       # 47.542M 35.248G
        from model_DualT.two_d.xcit import xcit_small_24_p8
        return xcit_small_24_p8()

    elif model_index == 1045:       #  39.048M 7.787G
        from model_DualT.two_d.t2t_vit import t2t_vit_19
        return t2t_vit_19()
    elif model_index == 1046:       # 21.441M 4.334G
        from model_DualT.two_d.t2t_vit import t2t_vit_14
        return t2t_vit_14()

    elif model_index == 1047:       # 21.955M 4.241G
        from model_DualT.two_d.deiT import deit_small_patch16_224
        return deit_small_patch16_224()
    elif model_index == 1048:       # 5.670M 1.075G
        from model_DualT.two_d.deiT import deit_tiny_patch16_224
        return deit_tiny_patch16_224()

    elif model_index == 1049:       # 5.670M 1.075G
        from model_DualT.two_d.xformer import Xformer_YXY
        return Xformer_YXY()


    elif model_index == 1052:       # 5.670M 1.075G
        from model_DualT.two_d.ml_mobileViT.cvnets.models.classification.mobilevit import MobileViT
        return MobileViT()
    elif model_index == 1053:       # 5.670M 1.075G
        # from options.opts import get_training_arguments
        from model_DualT.two_d.cvnets.models.classification.mobilevit import MobileViT
        return MobileViT(opts=None)
    # 这个原始代码的复现框架太复杂了，我们采用原文竞赛使用的Pytorch代码了

    elif model_index == 1055:       # 1.328M 333.053M
        from model_DualT.two_d.mobileVIT import MobileViT
        # from module_opt import InvertedResidual, MobileVitBlock
        model_cfg = {
            "xxs":{
                "features": [16, 16, 24, 24, 48, 48, 64, 64, 80, 80, 320],
                "d": [64, 80, 96],
                "expansion_ratio": 2,
                "layers": [2, 4, 3]
            },
        }
        cfg_xxs = model_cfg["xxs"]
        return MobileViT(256, cfg_xxs["features"], cfg_xxs["d"], cfg_xxs["layers"], cfg_xxs["expansion_ratio"])

    elif model_index == 1056:       # 2.378M 2.378M
        from model_DualT.two_d.mobileVIT import MobileViT
        # from module_opt import InvertedResidual, MobileVitBlock
        model_cfg = {
            "xs":{
                "features": [16, 32, 48, 48, 64, 64, 80, 80, 96, 96, 384],
                "d": [96, 120, 144],
                "expansion_ratio": 4,
                "layers": [2, 4, 3]
            },
        }
        cfg_xs = model_cfg["xs"]
        return MobileViT(256, cfg_xs["features"], cfg_xs["d"], cfg_xs["layers"], cfg_xs["expansion_ratio"])

    elif model_index == 1057:       # 5.627M 1.748G
        from model_DualT.two_d.mobileVIT import MobileViT
        # from module_opt import InvertedResidual, MobileVitBlock
        model_cfg = {
            "s":{
                "features": [16, 32, 64, 64, 96, 96, 128, 128, 160, 160, 640],
                "d": [144, 192, 240],
                "expansion_ratio": 4,
                "layers": [2, 4, 3]
            },
        }
        cfg_s = model_cfg["s"]
        return MobileViT(256, cfg_s["features"], cfg_s["d"], cfg_s["layers"], cfg_s["expansion_ratio"])



    elif model_index == 1059:       # 3.462M  63.846M
        from model_DualT.two_d.mobile_former import mobile_former_52m
        return mobile_former_52m()
    elif model_index == 1060:       # 4.578M 118.622M
        from model_DualT.two_d.mobile_former import mobile_former_96m
        return mobile_former_96m()
    elif model_index == 1061:       # 7.582M  144.365M
        from model_DualT.two_d.mobile_former import mobile_former_151m
        return mobile_former_151m()

    elif model_index == 1063:       #  421.304K 76.976M
        from model_DualT.two_d.convit import convit_tiny
        return convit_tiny()
    elif model_index == 1064:       # 421.464K 81.586M
        from model_DualT.two_d.convit import convit_small
        return convit_small()
    elif model_index == 1065:       # 421.784K 90.806M
        from model_DualT.two_d.convit import convit_base
        return convit_base()




    elif model_index == 1301:
        from model_DualT.three_d.arch import COVID19CT3D
        return COVID19CT3D()
    elif model_index == 1302:
        from model_DualT.three_d.densenet import DenseNet
        return DenseNet(sample_size=224, sample_duration=16,  num_classes=num_classes)
    elif model_index == 1303:
        from model_DualT.three_d.resnet import resnet18
        return resnet18(sample_size=224, sample_duration=16,  num_classes=num_classes)
    elif model_index == 13031:
        from model_DualT.three_d.resnet import resnet34
        return resnet34(sample_size=224, sample_duration=16,  num_classes=num_classes)
    elif model_index == 13032:
        from model_DualT.three_d.resnet import resnet50
        return resnet50(sample_size=224, sample_duration=16,  num_classes=num_classes)
    elif model_index == 13033:
        from model_DualT.three_d.resnet import resnet101
        return resnet101(sample_size=224, sample_duration=16,  num_classes=num_classes)
    elif model_index == 1304:
        from model_DualT.three_d.pre_act_resnet import resnet18
        return resnet18(sample_size=224, sample_duration=16,  num_classes=num_classes)
    elif model_index == 1305:
        from model_DualT.three_d.resnext import resnet50
        return resnet50(sample_size=224, sample_duration=16,  num_classes=num_classes)
    elif model_index == 1306:
        from model_DualT.three_d.wide_resnet import resnet50
        return resnet50(sample_size=224, sample_duration=16,  num_classes=num_classes)

    elif model_index == 1310:
        from model_DualT.three_d.cox3d.x3d import CoX3D        # 这个使用的不是torch，是continual
        return CoX3D()
    elif model_index == 1311:       # base
        from model_DualT.three_d.omnivision.models.swin_transformer import SwinTransformer3D
        return SwinTransformer3D(
        pretrained2d=False,
        patch_size=(2, 4, 4),
        embed_dim=128,
        depths=[2, 2, 18, 2],
        num_heads=[4, 8, 16, 32],
        window_size=(16, 7, 7),
        drop_path_rate=0.4,
        patch_norm=True)
    elif model_index == 1312:       # small     提高输出可读性Params(M)是 48.751M提高输出可读性MACs(G)是 68.210G
        from model_DualT.three_d.omnivision.models.swin_transformer import SwinTransformer3D
        return SwinTransformer3D(
        pretrained2d=False,
        patch_size=(2, 4, 4),
        embed_dim=96,
        depths=[2, 2, 18, 2],
        num_heads=[3, 6, 12, 24],
        window_size=(8, 7, 7),
        drop_path_rate=0.3,
        patch_norm=True,
        depth_mode="summed_rgb_d_tokens")
    elif model_index == 1313:       # 这是一个2D的
        from model_DualT.three_d.omnivision.models.vision_transformer import VisionTransformer
        from model_DualT.three_d.omnivision.models.vision_transformer import (
            Attention,
            Decoder,
            PadIm2Video,
            VisionTransformer,
        )
        from functools import partial
        return VisionTransformer(
        img_size=[3, 16, 224, 224],
        patch_size=[2, 16, 16],
        in_chans=3,
        embed_dim=768,
        depth=12,
        mlp_ratio=4,
        attn_target=partial(
            Attention,
            attn_drop=0,
            num_heads=12,
            proj_drop=0,
            qk_scale=False,
            qkv_bias=True,
        ))

    elif model_index == 1315:
        from model_DualT.three_d.omnivision.omnivore_model import omnivore_swinS
        return omnivore_swinS()
    elif model_index == 1316:       # 提高输出可读性Params(M)是 27.783M提高输出可读性MACs(G)是 34.916G
        from model_DualT.three_d.omnivision.omnivore_model import omnivore_swinT
        return omnivore_swinT()
    elif model_index == 1317:
        from model_DualT.three_d.omnivision.models.swin_transformer import SwinTransformer3D       # tiny
        return SwinTransformer3D(
        pretrained2d=False,
        patch_size=(2, 4, 4),
        embed_dim=96,
        depths=[2, 2, 6, 2],
        num_heads=[3, 6, 12, 24],
        window_size=(8, 7, 7),
        drop_path_rate=0.2,
        patch_norm=True,
        depth_mode="summed_rgb_d_tokens")

    elif model_index == 1318:   #提高输出可读性Params(M)是 33.905M提高输出可读性MACs(G)是 32.902G
        from model_DualT.three_d.omnivision.omni import omnivore_swinT
        return omnivore_swinT()

    elif model_index == 1319:   #Dual_steam     two_d
        from model_DualT.two_d.Dual_steam import ds_net_tiny
        return ds_net_tiny()
    elif model_index == 1320:   #Dual_steam     three_d
        from model_DualT.three_d.Dual_steam import ds_net_tiny
        return ds_net_tiny()
    elif model_index == 1328:   #Dual_steam     three_d
        from model_DualT.three_d.Dual_steam import ds_net_small
        return ds_net_small()

    elif model_index == 1321:   #Dual_steam     two_d
        from model_DualT.two_d.nextvit import nextvit_small
        return nextvit_small()
    elif model_index == 1322:   #Dual_steam     three_d
        from model_DualT.three_d.nextvit import nextvit_small
        return nextvit_small()
    elif model_index == 1323:   #1322 改进，优化小结构
        from model_DualT.three_d.nextvitA import nextvit_small
        return nextvit_small()
    elif model_index == 1324:   #1323改进， 之前组卷积让参数量少到四分之一，这里使用SC自校正卷积优化全部卷积  9.422M和11.239G
        # 因此可以偷懒，只修改MHCA            这里的结构为NCB之后添加NTB，然后NTB的后面部分是MHCA。
        from model_DualT.three_d.nextvitB import nextvit_small
        return nextvit_small()
    elif model_index == 1325:   #1324       这里的下采样在NCB模块前面，因此需要挪动到NTB末端。，这个只是方便写下一个交互模块
        # 但现在，我们不挪动这个位置，这个代码，还是单模态的，只是把这部分内容已经添加进去， 9.853M和11.798G
        from model_DualT.three_d.nextvitC import nextvit_small
        return nextvit_small()
    # 下面的代码这个电脑，显存带不动，暂时先调试好即可
    elif model_index == 1326:   #1324       三个模态，还不采用多模态交互,但代码基于1325     9.422M和 33.716G
        from model_DualT.three_d.nextvitD import nextvit_small
        return nextvit_small()
    elif model_index == 1327:   #1326       三个模+多模态交互,      11.199M和36.094G
        from model_DualT.three_d.nextvitE import nextvit_small
        return nextvit_small()

    elif model_index == 1330:   #Dual_steam     two_d
        from model_DualT.two_d.nextvit import nextvit_small
        return nextvit_small()
    elif model_index == 1331:   #Dual_steam     two_d
        from model_DualT.two_d.nextvit import nextvit_base
        return nextvit_base()
    elif model_index == 1332:   #Dual_steam     two_d
        from model_DualT.two_d.nextvit import nextvit_large
        return nextvit_large()

    # https://github.com/ubamba98/EfficientNet-PyTorch_3DConv
    elif model_index == 1340:   #1326       三个模+多模态交互,      11.199M和36.094G
        from model_DualT.three_d.Efficientnet3D import EfficientNet
        # model = EfficientNet.from_pretrained('efficientnet-b1', num_classes=23)
        # return EfficientNet.from_name('efficientnet-b0')
        return EfficientNet.from_name('efficientnet-b3')

    # elif model_index == 1070:
    #     from models_32.twotwo.ConvNeXt_main.models.convnext import convnext_tiny
    #     return convnext_tiny()
    # elif model_index == 1071:
    #     from models_32.twotwo.ConvNeXt_main.models.convnext import convnext_small
    #     return convnext_small()
    # elif model_index == 107:
    #     from models_32.twotwo.ConvNeXt_main.models.convnext import convnext_base
    #     return convnext_base()        # 改进3D
    elif model_index == 1342:
        from model_DualT.three_d.ConvNeXt.models.convnext import convnext_small
        return convnext_small()
    elif model_index == 1343:
        from model_DualT.three_d.ConvNeXt.models.convnext import convnext_base
        return convnext_base()

    # elif model_index == 1015:       # 提高输出可读性Params(M)是 11.894M提高输出可读性MACs(G)是 1.819G
    #     from model_DualT.two_d.poolformer import poolformer_s12
    #     return poolformer_s12()
    # elif model_index == 1016:       # 提高输出可读性Params(M)是 21.348M提高输出可读性MACs(G)是 3.405G
    #     from model_DualT.two_d.poolformer import poolformer_s24
    #     return poolformer_s24()
    elif model_index == 1346:
        from model_DualT.three_d.poolformer import poolformer_s24
        return poolformer_s24()
    elif model_index == 1347:
        from model_DualT.three_d.poolformer import poolformer_s36
        return poolformer_s36()

    # elif model_index == 1019:       # 提高输出可读性Params(M)是 21.926M提高输出可读性MACs(G)是 19.365G
    #     from model_DualT.two_d.coat import coat_small
    #     return coat_small()
    elif model_index == 1350:       # 提高输出可读性Params(M)是 24.385M提高输出可读性MACs(G)是 407.177G
        from model_DualT.three_d.coat import coat_small
        return coat_small()
    elif model_index == 1351:       # 提高输出可读性Params(M)是 6.619M提高输出可读性MACs(G)是 205.713G
        from model_DualT.three_d.coat import coat_tiny
        return coat_tiny()
    elif model_index == 1352:       #
        from model_DualT.three_d.coat import coat_mini
        return coat_mini()

    # elif model_index == 1021:       # 提高输出可读性Params(M)是 19.594M提高输出可读性MACs(G)是 4.062G
    #     from model_DualT.two_d.cls_cvt import ConvolutionalVisionTransformer
    #     return ConvolutionalVisionTransformer(in_chans=3, num_classes=num_classes, choice='cvt13')
    # elif model_index == 1022:       # 提高输出可读性Params(M)是 31.208M提高输出可读性MACs(G)是 6.512G
    #     from model_DualT.two_d.cls_cvt import ConvolutionalVisionTransformer
    #     return ConvolutionalVisionTransformer(in_chans=3, num_classes=num_classes, choice='cvt21')
    elif model_index == 1354:       # 提高输出可读性Params(M)是 19.594M提高输出可读性MACs(G)是 4.062G
        from model_DualT.three_d.cls_cvt import ConvolutionalVisionTransformer
        return ConvolutionalVisionTransformer(in_chans=3, num_classes=num_classes, choice='cvt13')
    elif model_index == 1355:       # 提高输出可读性Params(M)是 31.208M提高输出可读性MACs(G)是 6.512G
        from model_DualT.three_d.cls_cvt import ConvolutionalVisionTransformer
        return ConvolutionalVisionTransformer(in_chans=3, num_classes=num_classes, choice='cvt21')

    # elif model_index == 1023:       # 提高输出可读性Params(M)是 9.405M提高输出可读性MACs(G)是 1.233G
    #     from model_DualT.two_d.cmt import cmt_ti
    #     return cmt_ti()
    # elif model_index == 1025:       # 提高输出可读性Params(M)是 25.941M提高输出可读性MACs(G)是 3.912G
    #     from model_DualT.two_d.cmt import cmt_s
    #     return cmt_s()
    # elif model_index == 1026:       # 提高输出可读性Params(M)是 45.184M提高输出可读性MACs(G)是 6.866G
    #     from model_DualT.two_d.cmt import cmt_b
    #     return cmt_b()
    elif model_index == 1356:       #
        from model_DualT.three_d.cmt import cmt_ti
        return cmt_ti()
    elif model_index == 1357:       # 提高输出可读性Params(M)是 15.934M提高输出可读性MACs(G)是 16.016G
        from model_DualT.three_d.cmt import cmt_xs
        return cmt_xs()
    elif model_index == 1358:       # 提高输出可读性Params(M)是 27.278M提高输出可读性MACs(G)是 23.048G
        from model_DualT.three_d.cmt import cmt_s
        return cmt_s()
    elif model_index == 1359:       # 提高输出可读性Params(M)是 45.184M提高输出可读性MACs(G)是 6.866G
        from model_DualT.three_d.cmt import cmt_b
        return cmt_b()


    elif model_index == 1362:
        from model_DualT.threeL_d.mobilenetv3 import mobilenetv3
        return mobilenetv3(n_class=2)

    elif model_index == 1364:
        from model_DualT.threeL_d.ghostnet import ghostnet
        return ghostnet()

    elif model_index == 1366:
        from model_DualT.threeL_d.mobileVIT import MobileViT_XXS
        return MobileViT_XXS()
    elif model_index == 1368:
        # 提高输出可读性Params(M)是        #  2.028M
        # 提高输出可读性MACs(G)是        #  1.082G
        from model_DualT.threeL_d.mobileVIT3D import MobileViT_XXS
        return MobileViT_XXS()
    elif model_index == 1369:
        from model_DualT.threeL_d.mobileVIT3D import MobileViT_XS
        return MobileViT_XS()
    elif model_index == 1370:
        from model_DualT.threeL_d.mobileVIT3D import MobileViT_S
        return MobileViT_S()


    elif model_index == 1372:
        from model_DualT.threeL_d.mobileV import MobileViT_XXS
        return MobileViT_XXS()

    elif model_index == 1374:
        from model_DualT.threeL_d.mobileV3 import MobileViT_XXS
        return MobileViT_XXS()

    elif model_index == 1376:
        from model_DualT.threeL_d.mobileV5 import MobileViT_XXS
        return MobileViT_XXS()
    elif model_index == 1377:       # 第一个结构
        # 提高输出可读性Params(M)是        #  140.020K
        # 提高输出可读性MACs(G)是        #  69.852M
        from model_DualT.threeL_d.mobileV6 import MobileViT_XXS
        return MobileViT_XXS()

    elif model_index == 1384:       # 按Swin改
        # 1131
        # 提高输出可读性Params(M)是        #  668.592K
        # 提高输出可读性MACs(G)是        #  131.773M
        from model_DualT.threeL_d.mobileSwin import MobileViT_XXS
        return MobileViT_XXS()
    elif model_index == 1385:       # 按Swin改
        # 2262
        # 提高输出可读性Params(M)是        #  774.672K
        # 提高输出可读性MACs(G)是        #  175.450M
        from model_DualT.threeL_d.mobileSwin1 import MobileViT_XXS
        return MobileViT_XXS()
    elif model_index == 1386:       # 按Swin改
        # 2242
        # 提高输出可读性Params(M)是        #  752.592K
        # 提高输出可读性MACs(G)是        #  171.122M
        from model_DualT.threeL_d.mobileSwin2 import MobileViT_XXS
        return MobileViT_XXS()
    elif model_index == 1387:       # 按Swin改
        # 22-10-2
        # 提高输出可读性Params(M)是        #  818.832K
        # 提高输出可读性MACs(G)是        #  184.105M
        from model_DualT.threeL_d.mobileSwin3 import MobileViT_XXS
        return MobileViT_XXS()
    elif model_index == 1390:       # 第一个结构按Swin改
        # 22-18-2
        # 提高输出可读性Params(M)是        #  907.152K
        # 提高输出可读性MACs(G)是        #  201.416M
        # 去掉3*3卷积以后       AAAAAAAAAAA
        # 提高输出可读性Params(M)是        #  858.768K
        # 提高输出可读性MACs(G)是        #  186.928M
        from model_DualT.threeL_d.mobileSwinA import MobileViT_XXS
        return MobileViT_XXS()

    elif model_index == 1378:       # 第二个，加注意力机制
        # 提高输出可读性Params(M)是        #  140.020K
        # 提高输出可读性MACs(G)是        #  69.931M
        from model_DualT.threeL_d.mobileV6A import MobileViT_XXS
        return MobileViT_XXS()
    elif model_index == 1392:       # 按Swin改    第二个，加注意力机制
        # 22-18-2
        # 提高输出可读性Params(M)是        #  907.152K
        # 提高输出可读性MACs(G)是        #  202.039M
        from model_DualT.threeL_d.mobileSwinAA import MobileViT_XXS
        return MobileViT_XXS()

    elif model_index == 1394:       # 改自1392
        # 22-18-2
        # 提高输出可读性Params(M)是        #  962.880K
        # 提高输出可读性MACs(G)是        #  502.389M
        from model_DualT.threeL_d.mobileSwinB import MobileViT_XXS
        return MobileViT_XXS()

    elif model_index == 1395:       # 改自1394        通道数采用四分之一，比1392小太多
        # 22-18-2
        # 提高输出可读性Params(M)是        #  570.076K
        # 提高输出可读性MACs(G)是        #  200.185M        # 没有注意力机制
        # 22-18-2
        # 提高输出可读性Params(M)是        #  570.076K
        # 提高输出可读性MACs(G)是        #  200.704M
        from model_DualT.threeL_d.mobileSwinBA import MobileViT_XXS
        return MobileViT_XXS()
    elif model_index == 1396:       # 改自1394        将输入切开一半
        # 22-18-2                      BBBBBBBBBBBB         # 没有注意力机制
        # 提高输出可读性Params(M)是        #  574.828K
        # 提高输出可读性MACs(G)是        #  206.207M
        # 22-18-2                       CCCCCCCCC
        # 提高输出可读性Params(M)是        #  574.828K
        # 提高输出可读性MACs(G)是        #  206.311M
        from model_DualT.threeL_d.mobileSwinC import MobileViT_XXS
        return MobileViT_XXS()

    elif model_index == 1380:
        from model_DualT.threeL_d.mobileV8 import MobileViT_XXS
        return MobileViT_XXS()


    elif model_index == 1382:
        from model_DualT.two_d.ghostnetv2 import ghostnetv2_1x
        return ghostnetv2_1x()


    elif model_index == 1440:
        from model_DualT.threeL_d.EdgeNeXt.models.model import edgenext_base
        return edgenext_base()
    elif model_index == 1441:
        # 提高输出可读性Params(M)是        #  6.461M
        # 提高输出可读性MACs(G)是        #  2.024G
        from model_DualT.threeL_d.EdgeNeXt.models.model import edgenext_small
        return edgenext_small()
    elif model_index == 1442:
        from model_DualT.threeL_d.EdgeNeXt.models.model import edgenext_small
        return edgenext_small(pretrained=True)

    elif model_index == 1398:       # 改自1396有注意力机制
        # 22-18-2                      DDDDDDDDD
        # 提高输出可读性Params(M)是        #  958.828K
        # 提高输出可读性MACs(G)是        #  206.695M
        from model_DualT.threeL_d.mobileSwinD import MobileViT_XXS
        return MobileViT_XXS()

    elif model_index == 1399:       # 改自1398
        # 22-18-2                      FFFFFFFFFFF
        # 提高输出可读性Params(M)是        #  641.690K
        # 提高输出可读性MACs(G)是        #  381.612M
        from model_DualT.threeL_d.mobileSwinF import MobileViT_XXS
        return MobileViT_XXS()
    elif model_index == 1444:       # 改自1398
        # 22-18-2
        from model_DualT.threeL_d.mobileSwinFA import MobileViT_XXS
        return MobileViT_XXS()
    elif model_index == 1445:       # 2024.03.18
        # 22-18-2
        from model_DualT.threeL_d.mobileSwinFB import MobileViT_XXS
        return MobileViT_XXS()
    elif model_index == 1446:       # 2024.04.08
        # 22-18-2
        # 提高输出可读性Params(M)是        #  565.832K
        # 提高输出可读性MACs(G)是        #  152.140M
        from model_DualT.threeL_d.mobileSwinFC import MobileViT_XXS
        return MobileViT_XXS()
    elif model_index == 1447:       # 2024.04.10
        # 22-18-2
        # 提高输出可读性Params(M)是        #  552.728K
        # 提高输出可读性MACs(G)是        #  146.758M
        from model_DualT.threeL_d.mobileSwinFD import MobileViT_XXS
        return MobileViT_XXS()



    else:
        raise ValueError("The model_index does not exist.")
#     https://blog.csdn.net/weixin_31794609/article/details/112032129   pytorch预训练模型下载地址，但是很多模型都没有

